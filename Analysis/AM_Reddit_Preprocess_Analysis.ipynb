{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note, only using comments_df for now until we figure out if it is worth it to use the posts_df as well somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Import Packages, define functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import mysql.connector\n",
    "# some_file.py\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/brianmccabe/DataScience/Flatiron/mod4/Reddit_NLP/Scripts')\n",
    "#import config\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "import scipy\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can define a function that removes stopwords \n",
    "def process_comment(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_percentage(comment):\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    cap_count = 0\n",
    "    for item in tokens:\n",
    "        if item.isupper():\n",
    "            cap_count += 1\n",
    "    return cap_count/len(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_profanity(comment):\n",
    "    profane = pd.read_csv(\"/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/profane_words.csv\", header=None)\n",
    "    profane = list(profane.loc[:,0])\n",
    "    count = 0\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    for word in tokens:\n",
    "        if word in profane:\n",
    "            count += 1\n",
    "    return count/len(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    \n",
    "    unique_words = len(set(tokens))\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "    return unique_words / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stopwords and punctuations\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords += list(string.punctuation)\n",
    "stopwords += [\"n't\", \"' '\", \"'re'\",\"”\",\"``\",\"“\",\"''\",\"’\",\"'s\",\"'re\",\"http\",\"https\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.read_csv('/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/posts_df.csv', index_col=0)\n",
    "comments_df = pd.read_csv('/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/comments_df_(1).csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151515"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df.columns = ['id_num', 'post_title', 'post_author', 'post_upvote_ratio', 'post_id', 'post_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.columns = ['id_num', 'body', 'comment_id', 'parent_id', 'post_id', 'author', 'score', 'comment_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = '\\w+_(\\w+)'\n",
    "p = re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.post_id = comments_df.post_id.apply(lambda x: p.findall(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RID OF NEGATIVE SCORES (a negative score in a conservative subreddit could be a brigader for example)\n",
    "comments_df = comments_df[comments_df.score > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = comments_df[['body', 'comment_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "right    17116\n",
       "left     15773\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaning_map = {'right': 1, 'left': 0}\n",
    "df.comment_class = df.comment_class.map(leaning_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-67af6b43cc2d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_len'] = df['body'].map(lambda x: len(x))\n"
     ]
    }
   ],
   "source": [
    "df['text_len'] = df['body'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.text_len >= 100]\n",
    "df.drop('text_len', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9389\n",
       "1    9184\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9389\n",
       "0    9389\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "right = df[df.comment_class == 1]\n",
    "left = df[df.comment_class == 0]\n",
    "\n",
    "right_upsampled = resample(right,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(left), # match number in majority class\n",
    "                          random_state=42) \n",
    "df = pd.concat([left, right_upsampled])\n",
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['body']\n",
    "y = df['comment_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        As a Lesbian, I get a lot of backlash when peo...\n",
       "1        “*These are radical islamic terrorists and she...\n",
       "2        I hope Gov. Whitmer still has all that extra s...\n",
       "3        She's not wrong. I hope this woman goes places...\n",
       "4        The Orange Tweeter's irresponsible actions hav...\n",
       "                               ...                        \n",
       "18773    Oh heavens, she was pointed and laughed at.  S...\n",
       "18774    Atheist here and this bothers me.  Believe me ...\n",
       "18775    The good news is, if Biden wins and institutes...\n",
       "18776    Not exactly shocking that communities will ban...\n",
       "18777    Because I’m a woman living alone who is in a c...\n",
       "Name: body, Length: 18778, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Pronoun Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from Pronouns import Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Pronouns(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "    \n",
    "#     def count_pronouns(self, comment):\n",
    "#         comment = comment.lower()\n",
    "#         tokens = nltk.word_tokenize(comment)\n",
    "\n",
    "#         pos_tags = [i[1] for i in nltk.pos_tag(tokens)]\n",
    "#         count = 0\n",
    "#         pronouns = ['PRP','PRP$','WP','WP$']\n",
    "#         for pos in pos_tags:\n",
    "#             if pos in pronouns:\n",
    "#                 count += 1\n",
    "\n",
    "#         return count / len(tokens)\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         return pd.Series(X).apply(self.count_pronouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = Pronouns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pronouns()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouns.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns_vector = pronouns.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.106195\n",
       "1        0.048780\n",
       "2        0.058824\n",
       "3        0.107143\n",
       "4        0.029412\n",
       "           ...   \n",
       "18773    0.094340\n",
       "18774    0.054545\n",
       "18775    0.000000\n",
       "18776    0.037037\n",
       "18777    0.037037\n",
       "Name: body, Length: 18778, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouns_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_train, pro_test, y_train, y_test = train_test_split(pronouns_vector, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Capital Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capitalization_Normalizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def capital_percentage(self, lst):\n",
    "        return sum([1 if x.isupper() else 0 for x in lst]) / len(lst)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        tokens = pd.Series(X).apply(nltk.word_tokenize)\n",
    "        return tokens.apply(self.capital_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals = Capitalization_Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capitalization_Normalizer()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitals.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals_vector = capitals.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_train, cap_test, y_train, y_test = train_test_split(capitals_vector, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Profanity Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "profanity_count = X.apply(check_profanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_train, prof_test, y_train, y_test = train_test_split(profanity_count, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Text Length Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = X.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train, len_test, y_train, y_test = train_test_split(text_length, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatize X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply above function to data\n",
    "\n",
    "processed_comments = list(map(process_comment, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with lemmatized output\n",
    "lemmatized_output = []\n",
    "\n",
    "for comment in processed_comments:\n",
    "    lemmed = ' '.join([lemmatizer.lemmatize(w) for w in comment])\n",
    "    lemmatized_output.append(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this to 'lemmatized_output' if you are including lemma (see above)\n",
    "X_lem = lemmatized_output\n",
    "\n",
    "y_lem = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Lexical Diversity Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_div = pd.Series(X_lem).apply(lexical_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_train, lex_test, y_train, y_test = train_test_split(lex_div, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "        self.dim = 300\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Doc.vector defaults to an average of the token vectors.\n",
    "        # https://spacy.io/api/doc#vector\n",
    "        \n",
    "        return [self.nlp(text).vector for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "#         (\"reduce_dim\", TruncatedSVD(50)),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )\n",
    "# embeddings_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = embeddings_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"tfidf\", TfidfVectorizer()),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# tfidf_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = tfidf_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # individual pipelines minus the estimator step: \n",
    "# tfidf_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"tfidf\", TfidfVectorizer()),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# embeddings_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "#         (\"reduce_dim\", TruncatedSVD(50)),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_features = FeatureUnion(\n",
    "#     transformer_list=[\n",
    "#         (\"tfidf\", tfidf_pipeline),\n",
    "#         (\"embeddings\", embeddings_pipeline),\n",
    "#         #(try adding a pipeline that is just the dense columns)\n",
    "#     ]\n",
    "# )\n",
    "# final_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"combined_features\", combined_features),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = final_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining Sparse with Dense**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_input(pro_tr = None, pro_te = None, \n",
    "                     cap_tr = None, cap_te = None, \n",
    "                     prof_tr = None, prof_te = None, \n",
    "                     len_tr = None, len_te = None,\n",
    "                     lex_tr = None, lex_te = None):\n",
    "    \n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "    tfidf_data_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "    tfidf_data_test_lem = tfidf.transform(X_test_lem)\n",
    "    \n",
    "    \n",
    "    tfidf_data_train_lem = pd.DataFrame(tfidf_data_train_lem.toarray(), columns=tfidf.vocabulary_.keys())\n",
    "\n",
    "    tfidf_data_test_lem = pd.DataFrame(tfidf_data_test_lem.toarray(), columns=tfidf.vocabulary_.keys())\n",
    "    \n",
    "    print(\"Finished Part 1\")\n",
    "\n",
    "     \n",
    "    if str(type(pro_tr)) != str(type(None)) and str(type(pro_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xpronouns'] = pro_tr\n",
    "        tfidf_data_test_lem['Xpronouns'] = pro_te\n",
    "        print('finished pronoun_test')\n",
    "        \n",
    "    if str(type(cap_tr)) != str(type(None)) and str(type(cap_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xcapitals'] = cap_tr\n",
    "        tfidf_data_test_lem['Xcapitals'] = cap_te\n",
    "        print('finished capital_test')\n",
    "\n",
    "        \n",
    "    if str(type(prof_tr)) != str(type(None)) and str(type(prof_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xprofanity'] = prof_tr\n",
    "        tfidf_data_test_lem['Xprofanity'] = prof_te\n",
    "        print('finished profanity_test')\n",
    "    \n",
    "    if str(type(len_tr)) != str(type(None)) and str(type(len_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xlength'] = len_tr\n",
    "        tfidf_data_test_lem['Xlength'] = len_te\n",
    "        print('finished length_test')\n",
    "    \n",
    "    if str(type(lex_tr)) != str(type(None)) and str(type(lex_tr)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xlexical'] = lex_tr\n",
    "        tfidf_data_test_lem['Xlexical'] = lex_te\n",
    "        print('finished lexical_test')\n",
    "\n",
    "        \n",
    "    train_columns = tfidf_data_train_lem.columns\n",
    "    \n",
    "    tfidf_data_train_lem = scipy.sparse.csr_matrix(tfidf_data_train_lem)\n",
    "    \n",
    "    print(\"Finished train sparsing\")\n",
    "    \n",
    "    tfidf_data_test_lem = scipy.sparse.csr_matrix(tfidf_data_test_lem)\n",
    "    \n",
    "    print(\"Finished test sparsing\")\n",
    "\n",
    "    \n",
    "    return tfidf_data_train_lem, tfidf_data_test_lem, train_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dif dataframes to test models with, 1 with each feature appended to Tf IDF and one with all 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished pronoun_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished profanity_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished capital_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished length_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "pro_train2, pro_test2, pro_columns = classifier_input(pro_tr = pro_train, pro_te = pro_test)\n",
    "\n",
    "prof_train2, prof_test2, prof_columns = classifier_input(prof_tr = prof_train, prof_te = prof_test)\n",
    "\n",
    "cap_train2, cap_test2, cap_columns = classifier_input(cap_tr = cap_train, cap_te = cap_test)\n",
    "\n",
    "len_train2, len_test2, len_columns = classifier_input(len_tr = len_train, len_te = len_test)\n",
    "\n",
    "lex_train2, lex_test2, lex_columns = classifier_input(lex_tr = lex_train, lex_te = lex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished pronoun_test\n",
      "finished capital_test\n",
      "finished profanity_test\n",
      "finished length_test\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "combined_train, combined_test, combined_columns = classifier_input(pro_tr = pro_train, pro_te = pro_test, \n",
    "                                                                   prof_tr = prof_train, prof_te = prof_test, \n",
    "                                                                   cap_tr = cap_train, cap_te = cap_test, \n",
    "                                                                   len_tr = len_train, len_te = len_test, \n",
    "                                                                   lex_tr = lex_train, lex_te = lex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, accuracy, f1]\n",
       "Index: []"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns = ['model','accuracy','f1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Pronouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.9341\n",
      "\n",
      "F1 Score: 0.9327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_pro = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_pro.fit(pro_train2, y_train_lem)\n",
    "rf_test_preds = rfc_pro.predict(pro_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  accuracy        f1\n",
       "0  rfc_pro  0.934124  0.932712"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_pro', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(pro_columns, rfc_pro.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.044628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.027478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.008624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.008293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xpronouns</td>\n",
       "      <td>0.007651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>street</td>\n",
       "      <td>0.007077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>biggly</td>\n",
       "      <td>0.005618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vu</td>\n",
       "      <td>0.005386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amend</td>\n",
       "      <td>0.005374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ojelr5pxgdu</td>\n",
       "      <td>0.004656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0          hoa    0.044628\n",
       "1  underpaying    0.027478\n",
       "2         bees    0.008624\n",
       "3       jurist    0.008293\n",
       "4    Xpronouns    0.007651\n",
       "5       street    0.007077\n",
       "6       biggly    0.005618\n",
       "7           vu    0.005386\n",
       "8        amend    0.005374\n",
       "9  ojelr5pxgdu    0.004656"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_test_lem, rf_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Right', 'Left'], yticklabels=['Right', 'Left'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RCF Profanity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Profanity\n",
      "Testing Accuracy: 0.9335\n",
      "\n",
      "F1 Score: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_prof = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_prof.fit(prof_train2, y_train_lem)\n",
    "rf_test_preds = rfc_prof.predict(prof_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Profanity')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy        f1\n",
       "0   rfc_pro  0.934124  0.932712\n",
       "1  rfc_prof  0.933516  0.932238"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(prof_columns, rfc_prof.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.028132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xprofanity</td>\n",
       "      <td>0.011027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.008421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.008107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>street</td>\n",
       "      <td>0.006794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>biggly</td>\n",
       "      <td>0.005490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vu</td>\n",
       "      <td>0.005379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amend</td>\n",
       "      <td>0.005196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ojelr5pxgdu</td>\n",
       "      <td>0.004517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0          hoa    0.041700\n",
       "1  underpaying    0.028132\n",
       "2   Xprofanity    0.011027\n",
       "3         bees    0.008421\n",
       "4       jurist    0.008107\n",
       "5       street    0.006794\n",
       "6       biggly    0.005490\n",
       "7           vu    0.005379\n",
       "8        amend    0.005196\n",
       "9  ojelr5pxgdu    0.004517"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's interesting that we have a lower accuracy with this model, yet our newly added feature ranks as higher importance than pronouns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Capital**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9367\n",
      "\n",
      "F1 Score: 0.9355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_cap = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_cap.fit(cap_train2, y_train_lem)\n",
    "rf_test_preds = rfc_cap.predict(cap_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy        f1\n",
       "0   rfc_pro  0.934124  0.932712\n",
       "1  rfc_prof  0.933516  0.932238\n",
       "2   rfc_cap  0.936711  0.935484"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_cap', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(cap_columns, rfc_cap.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.044085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.027164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.008479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.008161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>street</td>\n",
       "      <td>0.007162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xcapitals</td>\n",
       "      <td>0.006070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>biggly</td>\n",
       "      <td>0.005689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vu</td>\n",
       "      <td>0.005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amend</td>\n",
       "      <td>0.005305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ojelr5pxgdu</td>\n",
       "      <td>0.004661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0          hoa    0.044085\n",
       "1  underpaying    0.027164\n",
       "2         bees    0.008479\n",
       "3       jurist    0.008161\n",
       "4       street    0.007162\n",
       "5    Xcapitals    0.006070\n",
       "6       biggly    0.005689\n",
       "7           vu    0.005575\n",
       "8        amend    0.005305\n",
       "9  ojelr5pxgdu    0.004661"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.939\n",
      "\n",
      "F1 Score: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_len = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_len.fit(len_train2, y_train_lem)\n",
    "rf_test_preds = rfc_len.predict(len_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy        f1\n",
       "0   rfc_pro  0.934124  0.932712\n",
       "1  rfc_prof  0.933516  0.932238\n",
       "2   rfc_cap  0.936711  0.935484\n",
       "3   rfc_len  0.938993  0.937510"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_len', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Lexical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9404\n",
      "\n",
      "F1 Score: 0.9391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_lex = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_lex.fit(lex_train2, y_train_lem)\n",
    "rf_test_preds = rfc_lex.predict(lex_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Lexical')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy        f1\n",
       "0            rfc_pro  0.934124  0.932712\n",
       "1           rfc_prof  0.933516  0.932238\n",
       "2            rfc_cap  0.936711  0.935484\n",
       "3            rfc_len  0.938993  0.937510\n",
       "4            rfc_len  0.940362  0.939112\n",
       "5       rfc_combined  0.936254  0.934847\n",
       "6  grid_rfc_combined  0.934581  0.933147\n",
       "7            svm_pro  0.935798  0.934165\n",
       "8           svm_prof  0.935798  0.934021\n",
       "9            rfc_lex  0.940362  0.939112"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_lex', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Combined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9363\n",
      "\n",
      "F1 Score: 0.9348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_combined = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_combined.fit(combined_train, y_train_lem)\n",
    "rf_test_preds = rfc_combined.predict(combined_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0       rfc_pro  0.934124  0.932712\n",
       "1      rfc_prof  0.933516  0.932238\n",
       "2       rfc_cap  0.936711  0.935484\n",
       "3       rfc_len  0.938993  0.937510\n",
       "4       rfc_len  0.940362  0.939112\n",
       "5  rfc_combined  0.936254  0.934847"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_combined', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(combined_columns, rfc_combined.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.035065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.030333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.009594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xprofanity</td>\n",
       "      <td>0.009543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xlength</td>\n",
       "      <td>0.007808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>street</td>\n",
       "      <td>0.007630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.007607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Xpronouns</td>\n",
       "      <td>0.007378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Xcapitals</td>\n",
       "      <td>0.005844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vu</td>\n",
       "      <td>0.005671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0          hoa    0.035065\n",
       "1  underpaying    0.030333\n",
       "2         bees    0.009594\n",
       "3   Xprofanity    0.009543\n",
       "4      Xlength    0.007808\n",
       "5       street    0.007630\n",
       "6       jurist    0.007607\n",
       "7    Xpronouns    0.007378\n",
       "8    Xcapitals    0.005844\n",
       "9           vu    0.005671"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gridsearch RFC Combined**\n",
    "- currently this has been replaced with combined(lexical + profanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 55, 60, 65, 70, 75, 80, 85, 90, 95]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(50,100,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = list(range(50,250,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 33.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 39.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 60, 70, 80, 90, 100, 110, 120,\n",
       "                                          130, 140, 150, 160, 170, 180, 190,\n",
       "                                          200, 210, 220, 230, 240]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'criterion': ['gini','entropy'],\n",
    "              'max_features': ['auto','sqrt','log2']\n",
    "        }\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, refit = True, verbose = 3, n_jobs = -1, scoring='accuracy')\n",
    "\n",
    "grid.fit(lex_prof_train, y_train_lem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_test_preds = grid.predict(lex_prof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'log2',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 240,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_lem, grid_test_preds)\n",
    "f1 = f1_score(y_test_lem, grid_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid RFC with Lemmatization Features and Combined\n",
      "Testing Accuracy: 0.9402\n",
      "\n",
      "F1 Score: 0.9383\n"
     ]
    }
   ],
   "source": [
    "print('Grid RFC with Lemmatization Features and Combined')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rfc_lex_prof</td>\n",
       "      <td>0.941427</td>\n",
       "      <td>0.939437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>grid_rfc_comb_lex_prof</td>\n",
       "      <td>0.940210</td>\n",
       "      <td>0.938295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  accuracy        f1\n",
       "0                  rfc_pro  0.934124  0.932712\n",
       "1                 rfc_prof  0.933516  0.932238\n",
       "2                  rfc_cap  0.936711  0.935484\n",
       "3                  rfc_len  0.938993  0.937510\n",
       "4                  rfc_len  0.940362  0.939112\n",
       "5             rfc_combined  0.936254  0.934847\n",
       "6        grid_rfc_combined  0.934581  0.933147\n",
       "7                  svm_pro  0.935798  0.934165\n",
       "8                 svm_prof  0.935798  0.934021\n",
       "9                  rfc_lex  0.940362  0.939112\n",
       "10            rfc_lex_prof  0.941427  0.939437\n",
       "11  grid_rfc_comb_lex_prof  0.940210  0.938295"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'grid_rfc_comb_lex_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Combined (Lexical + Prof)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished profanity_test\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "lex_prof_train, lex_prof_test, lex_prof_columns = classifier_input(prof_tr = prof_train, prof_te = prof_test, \n",
    "                                                                   lex_tr = lex_train, lex_te = lex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9414\n",
      "\n",
      "F1 Score: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_lex_prof = RandomForestClassifier(n_estimators=200,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_lex_prof.fit(lex_prof_train, y_train_lem)\n",
    "rf_test_preds = rfc_lex_prof.predict(lex_prof_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rfc_lex_prof</td>\n",
       "      <td>0.941427</td>\n",
       "      <td>0.939437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  accuracy        f1\n",
       "0             rfc_pro  0.934124  0.932712\n",
       "1            rfc_prof  0.933516  0.932238\n",
       "2             rfc_cap  0.936711  0.935484\n",
       "3             rfc_len  0.938993  0.937510\n",
       "4             rfc_len  0.940362  0.939112\n",
       "5        rfc_combined  0.936254  0.934847\n",
       "6   grid_rfc_combined  0.934581  0.933147\n",
       "7             svm_pro  0.935798  0.934165\n",
       "8            svm_prof  0.935798  0.934021\n",
       "9             rfc_lex  0.940362  0.939112\n",
       "10       rfc_lex_prof  0.941427  0.939437"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_lex_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open('rfc_lex_prof.pickle', 'wb') as f:\n",
    "    pickle.dump(rfc_lex_prof, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with Pronouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.9358\n",
      "\n",
      "F1 Score: 0.9342\n"
     ]
    }
   ],
   "source": [
    "svc_pro = SVC(verbose=1)\n",
    "svc_pro.fit(pro_train2, y_train_lem)\n",
    "rf_test_preds = svc_pro.predict(pro_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy        f1\n",
       "0            rfc_pro  0.934124  0.932712\n",
       "1           rfc_prof  0.933516  0.932238\n",
       "2            rfc_cap  0.936711  0.935484\n",
       "3            rfc_len  0.938993  0.937510\n",
       "4            rfc_len  0.940362  0.939112\n",
       "5       rfc_combined  0.936254  0.934847\n",
       "6  grid_rfc_combined  0.934581  0.933147\n",
       "7            svm_pro  0.935798  0.934165"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_pro', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with Profanity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Profanity\n",
      "Testing Accuracy: 0.9358\n",
      "\n",
      "F1 Score: 0.934\n"
     ]
    }
   ],
   "source": [
    "svc_prof = SVC(verbose=1)\n",
    "svc_prof.fit(prof_train2, y_train_lem)\n",
    "rf_test_preds = svc_prof.predict(prof_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Profanity')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy        f1\n",
       "0            rfc_pro  0.934124  0.932712\n",
       "1           rfc_prof  0.933516  0.932238\n",
       "2            rfc_cap  0.936711  0.935484\n",
       "3            rfc_len  0.938993  0.937510\n",
       "4            rfc_len  0.940362  0.939112\n",
       "5       rfc_combined  0.936254  0.934847\n",
       "6  grid_rfc_combined  0.934581  0.933147\n",
       "7            svm_pro  0.935798  0.934165\n",
       "8           svm_prof  0.935798  0.934021"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Capitals\n",
      "Testing Accuracy: 0.9356\n",
      "\n",
      "F1 Score: 0.9339\n"
     ]
    }
   ],
   "source": [
    "svc_cap = SVC(verbose=1)\n",
    "svc_cap.fit(cap_train2, y_train_lem)\n",
    "rf_test_preds = svc_cap.predict(cap_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Capitals')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.936693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm_cap</td>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.933937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0       rfc_pro  0.934124  0.932712\n",
       "1      rfc_prof  0.933516  0.932238\n",
       "2       rfc_cap  0.936711  0.935484\n",
       "3  rfc_combined  0.938080  0.936693\n",
       "4       svm_pro  0.935798  0.934165\n",
       "5      svm_prof  0.935798  0.934021\n",
       "6       svm_cap  0.935646  0.933937"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_cap', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Capitals\n",
      "Testing Accuracy: 0.9355\n",
      "\n",
      "F1 Score: 0.9338\n"
     ]
    }
   ],
   "source": [
    "svc_combined = SVC(verbose=1)\n",
    "svc_combined.fit(combined_train, y_train_lem)\n",
    "rf_test_preds = svc_combined.predict(combined_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Capitals')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.936693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm_cap</td>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.933937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_combined</td>\n",
       "      <td>0.935494</td>\n",
       "      <td>0.933833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0       rfc_pro  0.934124  0.932712\n",
       "1      rfc_prof  0.933516  0.932238\n",
       "2       rfc_cap  0.936711  0.935484\n",
       "3  rfc_combined  0.938080  0.936693\n",
       "4       svm_pro  0.935798  0.934165\n",
       "5      svm_prof  0.935798  0.934021\n",
       "6       svm_cap  0.935646  0.933937\n",
       "7  svm_combined  0.935494  0.933833"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_combined', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MN Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes model accuracy\n",
      "Testing Accuracy: 0.8801\n",
      "\n",
      "F1 Score: 0.8789\n"
     ]
    }
   ],
   "source": [
    "mnb_lemma = MultinomialNB()\n",
    "mnb_lemma.fit(tfidf_data_train_lem, y_train_lem)\n",
    "mnb_test_preds = mnb_lemma.predict(tfidf_data_test_lem)\n",
    "\n",
    "mnb_acc_score_lem = accuracy_score(y_test_lem, mnb_test_preds)\n",
    "mnb_f1_score_lem = f1_score(y_test_lem, mnb_test_preds)\n",
    "print('Multinomial Naive Bayes model accuracy')\n",
    "print(\"Testing Accuracy: {:.4}\".format(mnb_acc_score_lem))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(mnb_f1_score_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAEJCAYAAACHaNJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdh0lEQVR4nO3deVRV9d7H8ffhHAYRvGpFimjXKRzK1FK0Qc2JbkWIIt5rommlljncJNJUKrQ01FQyS8qxrBzqUXlW1yFFHDK9aqaUimmaI4gDJIoMnucP7z3lU+yjyZnk81rLtTh7+n03rT7s/fv99j4mq9VqRUSkFF6uLkBE3JtCQkQMKSRExJBCQkQMKSRExJBCQkQMWVxdwLUoyjno6hLkOgSEtHV1CXKdLhUcKXWdriRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJDF1QXcTFJXrmXOJ0swYcLPz5eRwwZSs0Z1EidOZ9/+A1So4EeXRzvxZPdIAHbv2cdb01K4eLGAy5cv069XdyLC2wOwbedu3n53FgWFhQRWrMi4US9Ss0Z1V55eufFERDizZ0/l1tsa4uXlRdJbY+jcuR0Wi4UpU2bywYcfA9C2bWvemjAGi8XC6TNniYt7jd2797i4+rKnkCgjPx0+yuR3P2Tx7OncdmtV1n+9lWGjxtGyWRP8/f1YtmAmly9fZsiIRGoEV6Pt/S3556g3GDvyn7Ru0YyT2aeI6TuYJo1C8fX1YejIsXww9U0ahdbjo0VLGTf5XWa+Pc7Vp3nTq1f3r0yYMBqTyQTAs8/0on79OjRr3pHAwADWpy/l250ZZGYeYOFnKfyj50DS0jYRemddliyZxb33daawsNDFZ1G2HHq7MXPmzN8te/vttx3ZpMv4+Hjz+ohh3HZrVQAaN7yTnNNnydibSUR4B8xmM97e3rS5vyWr0zZSWFjEc32fpHWLZgBUC7qNKpX/QlZ2DqvTNvJgq/toFFoPgJjIR3l56ACXnVt5UaGCH3PmJBMfn2hbFhkZzrz5iygpKeHcuVwWLV5Oz39EUa9ebXLzfiEtbRMA+zIPkJd3nlatmruqfIdxyJXEpEmTOH36NGvXruXQoUO25cXFxezatYsXX3zREc26VI3qt1Oj+u0AWK1WkpJTePjBMAICKpK6cg3NmjSiqLCI1es2YbGY8fX1oVtEuG3/xcu+JP/iRZrc1YCVaRvwr+BHXMJ4Dv18lOq3BxE/pL+rTq3cePfdCXw4awG7M369ZQgJCebo0eO2z8eOneDuuxqyf/9BKvr707FjG776aj333nsPjRrdSbVqt7uidIdySEh07tyZAwcO8M0339CyZUvbcrPZzKBBgxzRpNu4cLGA0W9M5mTWKd7/z+3BpOkf0v2pF7j1liq0btGMnRk/XLXPhx8t4uPFS3l/8jj8fH0pLi5h3aYtzJ8xkTtq1uDjxcsY9so4Pp/3ritOqVwY0L83xcUlzJu3kDvuCLEt9/Lywmq12j6bTCZKSkr45ZfzdI95htdfj2f8m6PYuHEL69ZtuuluNcBBIdGkSROaNGlCx44dCQwMdEQTbunEyWwGvfwade6oyezpb+Hn68uJk9kMH/Q0f6l05feQMu8zatUIBqCwsJBRb7zNgUM/s2DmFNuVyG23VqXZ3Y24o2YNALo+Hs6Eqe9TcOkSfr6+rjm5m1xsbHf8/SuwdcsKfHy8qVDBj61bVnD02AmqV69m26569ds5duwkJpOJ8+fz6dw5xrYuY3c6Bw4cckH1juXQPokVK1bQunVrGjZsSMOGDWnQoAENGzZ0ZJMuk59/gb6DX6Zj2weYlDjS9j/zwqVfMv2DjwDIOXOWL/53JY92bgfAiMSJnM+/wMfvv20LCICObe7n290/cPT4SQC+St9Evdp3KCAc6MGHImh+b0dahj1CZJc+XLxYQMuwR1i+bAVP9YnBbDbzl79UIqb7EyxPXYnVamXZ0vk0b94EgOjoCAoKLml043q99957zJ8/n/r16zuyGbfwyeepHD+ZzZr0r1mT/rVt+TtvJTBh6ky69BqI1Wpl0DOx3N0wlJ0Ze1iVtpG/1qxB7MDhtu1ffL4fD4Tdy+jhgxg6cizFxcVUqhTA5HGvuOK0yr2ZKR9Rp84dbPv3Snx8fPjwwwVs2PANAH2eGsx7M97Cx8ebkyez6R7zjIurdQyT9bc3XGWse/fuLF68+IaPU5RzsAyqEWcJCGnr6hLkOl0qOFLqOodcSSxduhSA4OBgnnvuOTp06IDF8mtTXbp0cUSzIuIADgmJLVu2AODv74+/vz/bt2+/ar1CQsRzOPR2o6zodsOz6HbD8zj9duO/OnfuTElJie2zyWTCz8+POnXq8PLLL1OjRg1HNi8iZcChIdGmTRtCQkKIjo4GYPny5ezevZv27dszatQo5s6d68jmRaQMOHSexPbt23nqqacICAggICCAnj17sm/fPjp16kRubq4jmxaRMuLQkPDy8mLDhg22zxs2bMDHx4ecnByKi4sd2bSIlBGHdlxmZmYyYsQIjh07BkCtWrWYMGECK1asIDg4mKioqGs6jjouPYs6Lj2PUcelU0Y3cnNzMZvNBAQE/Kn9FRKeRSHheZw+ujFmzBjGjh1LbGys7eUd/2UymZg3b54jmhURB3BISPTo0YODBw8SExPD7bf/+uBSTk4O06ZNc0STIuIgDum4TEtLo1u3biQkJFBcXEzLli3ZtWsXo0ePJiQkxP4BRMRtlNon8f333xvu2Lhx41LXdejQgU8//ZTs7GySk5O5fPkyWVlZxMfH89BDD113keqT8Czqk/A8f6pPYvDgwaXuZDKZWLNmTanrK1asSFBQEEFBQezatYsuXbowc+ZMzGbzNZYsIu6i1JBYu3btnz6ol9evdzFVqlRhxIgRf/pYIuJadvsk8vPzSUxMpE+fPpw7d46EhATy8/MN9/ntiIafn9+NVykiLmN3dGPcuHEEBQVx+vRpfH19OX/+PAkJCUyePLnUffbv30+HDh0AyMrKsv1stVrt3qqIiHuxGxJ79uxh/PjxpKenU6FCBSZNmsTjjz9uuM/KlSvLrEARcS27IfHb/gWAkpKS3y37//QIuMjNw25ItGjRgokTJ1JQUMCGDRtYsGABYWFhzqhNRNyA3Y7LuLg4/P39CQwMZMqUKYSGhhIfH++M2kTEDVzzA17nz5/H29sbXxd894MmU3kWTabyPEaTqexeSRw6dIiYmBjCwsK499576d27NydOnCjTAkXEfdkNiYSEBKKjo9m5cyc7duygU6dOjB492hm1iYgbsBsSeXl5xMTE4O3tjY+PD7GxseTk5DijNhFxA3ZDolatWnz33Xe2z3v37qVWrVoOLUpE3EepQ6ARERHAlWnZPXv2JDQ0FC8vL/bu3UvdunWdVqCIuFapITFmzBhn1iEibqrUkGjZsqXt53PnznHx4kWsVislJSX8/PPPTilORFzP7ozLadOmkZKSAoDZbKaoqIh69eqRmprq8OJExPXsdlwuW7aMtLQ0wsPDWbVqFePHj6devXrOqE1E3IDdkKhatSpBQUHUqVOHvXv30qVLFzIzM51Rm4i4AbshYbFY+Pnnn6lTpw7btm2juLiYS5cuOaM2EXEDdkNiwIABjBkzhnbt2rFq1SratWunp0BFypHr+gavixcvcvjwYRo0aODImn5HD3h5Fj3g5Xn+1Nuyx40bZ3hQPb8hUj6UGhKVK1d2Zh0i4qac8oXBN0q3G55Ftxue54beJyEi5ZtCQkQMKSRExFCpHZfTp0833PGFF14o82JExP2UGhJnz54F4ODBg/z000907NgRi8XCmjVrCA0NdVqBIuJadkc3evfuzdSpU6latSoAubm5PP/88yxYsMApBYJGNzyNRjc8zw2Nbpw6dcoWEACVKlXi9OnTZVOZiLg9u++TCA0NZeTIkURGRmK1WlmyZAn33HOPM2oTETdg93bj/PnzJCcns3nzZgDatGnD4MGD8fPzc0qBoNsNT6PbDc9jdLtxTTMuCwoKOHToEHfeeSeXLl2iQoUKZVqgPQoJz6KQ8Dw31Cexc+dOOnbsyMCBA8nOzqZdu3bs2LGjTAsUEfdl90qiZ8+eJCYmEhcXx9KlS0lPTyc5OZnPP//cWTVi8anhtLbkxl048KWrS5Dr5FOz9H5Gu1cSBQUFV73Tsm3btpSUlJRNZSLi9q7p9XW5ubmYTCbgyuQqESk/7A6BDhw4kF69epGTk8OLL77Ipk2bSExMdEZtIuIGrml04/Dhw2zatInLly/TunVrp3/Nn/okPIv6JDzPDfVJvPLKK9xxxx307NmTXr16UbduXYYMGVKmBYqI+yr1duPVV18lKyuL7du3c+bMGdvy4uJijhwpfUxVRG4upYZEdHQ0+/fvZ9++fYSHh9uWm81mmjZt6pTiRMT17PZJnDx5kiNHjtCiRQvOnTvHtm3b6Nixo7PqA9Qn4WnUJ+F5bqhP4tNPPyU5ORm4MmciJSWFGTNmlF11IuLW7IbEmjVrmD17NgDVqlXj448/5ssv9ZdCpLywGxJFRUV4e3vbPnt7e9smVonIzc/uZKrmzZszfPhwoqOjMZlMLF26VO+TEClH7HZcXrhwgWnTprF582YsFgutW7fmhRdecOrj4uq49CzquPQ8Rh2XHvENXgoJz6KQ8DxGIVHq7cbQoUOZNm0aERERf7g+NTX1xisTEbdXakg8++yzAIwZM8ZpxYiI+yk1JKpWrcrx48cJCQlxZj0i4mZKDYnHHnsMk8mE1WqloKCAihUrYjabycvL45ZbbmHjxo3OrFNEXKTUkPj2228BSEhIICwsjMceewy4Mrnqq6++ck51IuJydidTZWRk2AICoEOHDuzdu9ehRYmI+7AbEpcvX2bLli22z+vXr9eMS5FyxO6My9GjRzNs2DC8vb2xWq1YrVbeffddZ9QmIm7gmiZTFRUVkZmZCVz52j+LxW62lClNpvIsmkzleW7oUfH8/HzGjx9PUlISNWrUIDExkfz8/DItUETcl92QGDduHIGBgZw+fRpfX1/Onz9PQkKCM2oTETdgNyT27NnDP//5TywWCxUqVGDSpEns2bPHGbWJiBuwGxJeXldvUlJS8rtlInLzstsD2aJFCyZOnEhBQQEbNmxgwYIFhIWFOaM2EXEDdi8J4uLi8Pf3JzAwkClTphAaGkp8fLwzahMRN2B3CHTy5MkMHz7cWfX8IQ2BehYNgXqeGxoCXbduXVnWIiIexm6fREhICP369aN58+ZUrFjRtrxv374OLUxE3IPdkKhcuTIAx44dc3gxIuJ+rvkdl7m5uZjNZgICAhxd0++oT8KzqE/C89xQn8TBgwfp1q0b999/P2FhYfTq1Yvjx4+XaYEi4r7shsTIkSPp3r07O3fu5NtvvyU8PJxRo0Y5ozYRcQN2Q+LixYv8/e9/x9vbGx8fH2JjY8nJyXFGbSLiBuyGRJ06ddixY4ftc2Zmpl6OK1KO2B3dOH78OLGxsbb3SPzwww/cdttttu/j0PdviNzc7IZEXFycM+oQETdlNyRatmzpjDpExE3pmW8RMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDzv2+vnLm+eeeYsCA3litVg4ePMyAgS8x/Z3x1K37V9s2tf9ak/UbviGqa1/atb2fpKQELBYzZ06f48W4V9m16wfXnUA5kPrVeuYuSsVkAj9fX0YO6kuDerV5851ZbPvP7/6hsGYM7x+LyWRi3eZtjEp6l+pBt9qOMW9KIv4V/HhnzkJWpn9NBT9fmjYK5aXneuPr4+OqUysz1/zSGVfyxJfONG92N4sWfkDz+zqRl/cLSRPGEBAYwPODXrZtc9+997DwsxTaPhxFXt4vHNj/DT3+PoC1aRsJDa3LF5/PoVnzjhQWFrrwTK6fp7x05qcjx+k3/DUWvfcWt91ShfVbdjB26gcMeqoHqavTSXlrDJetl4kdMoa+PZ4gvG1rpn74CRX9/Xi2Z9erjvU/K9JY8D9fMnvya1QKqMj7Hy/hfP4F4gb0dtHZXZ8beumM/Dk7vt1Ng0YPkpf3C76+vgTXqMaZM2dt6729vZk9eyovxr3K0aPHqV+vNrm5v7A2bSMA+/YdIC/vF1q3utdVp3DT8/G28PqLA7ntlioANL6zLjlnz1FYVMTFgksUFhVRVFRMUXExvj7eAOz8YR9bvv2ebv1fos+wBNvVxg/7D9L+/hZUCrjyHtiOD4axev0W15xYGXNoSOTm5v5uWXl6V2ZxcTFPPBHO4Z+28dCDYcydt9C2rl/ff3DieBbLlq0AIHP/QSpW9KdTxzbAlauMxo1CqVY9yCW1lwc1qgXRplVzAKxWKxPfn8fDre+j2986UCmgIh3+PpCHY/pTK/h22rW+D4DKlQKJiejEkplJDH26J8NencTJU6dp0qA+6zZv52xuHpcvX2b56nRO/eaPgidzSEicOHGC48eP8+STT9p+Pn78OEeOHOHpp592RJNua/nylVQLvpvEsW/z5f8uwGQyATB06LO8OX6abbtffjlPt+h+jHh5MNu3raZXr2jS0jZRWFjkqtLLjQsXCxg+dgpHjmXx2vCBvPfRYqpUrkT64g/46tP3yf0ln3mLr7wSYeprcXRu0wqTyUTzuxvQtPGdbN6+i4hObejcphVPxyUSO3QMtWvWwNtyc3T5OeQskpOT2bJlC9nZ2Tz55JO/Nmax0K5dO0c06Xbq1v0r1W6/jU1f/xuAOXM/Y8a7E6hSpTK1agVjMZtJX7/Ztr3JZOJ8/gU6dOpuW/bD9xs4cOCQs0svV05k5fDCmLeoU6sGsya/ip+vD2s2bmXkC33x9rbg7W3hic5tWb3+G6L+1p6Fy1fyzD+ibGFvtYLFYiY37zyPdniQZ3pGAbDz+33UCq7mylMrMw65kggNDWXt2rUMGTKEtWvX2v6tWrWKV155xRFNup3q1YJY8PF73PKf+92ePbuS8f0+zpw5S5uHWpO2btNV21utVlKXzefe5k0A6N79CQoKCjS64UD5Fy7Sd/hrdHywJRNHD8PP98pIRMN6tVm57kqAFxUXs27zNpo0rE/FChX4bNlKvtpwpa9hz/6fyNj3Iw+2aMr3mQcY9uokioqLKS4pYdZnS3msw4MuO7ey5JArifnz5/Pwww+zfPlyIiIi+P8DKMHBwY5o1q1s3LSV8ROSWfPVEoqLSzhx/CTdovsBUK9ebQ4fPvq7fWJ7v8D770/Ex8ebkyey6RZdvm7NnO3TpSs4kX2KNZu2smbTVtvyD5MSeHP6LCL6DsPs5UVYs7vo1yMSs9mL5MR43pw+mxnzF2M2ezFx9DCq/KUS9993D9t2/UC3/i9hvXyZhx9oQWy3x114dmXHIUOgycnJLF++nJMnTxIUdHXHm8lkYs2aNdd1PE8cAi3PPGUIVH5lNATq0HkSr776Kq+//voNH0ch4VkUEp7HZfMkXn/9dVJTU5kyZQoXL15k6dKljmxORBzAoSExadIk0tPTWbVqFcXFxXz++edMmDDBkU2KSBlzaEhs3LiRiRMn4uvrS2BgIHPmzGH9+vWObFJEyphDQ8LL68rh/zumXFhYaFsmIp7BoVPCHnnkEYYNG0Zubi5z585l+fLlPP74zTEsJFJeODQk+vfvz4YNGwgODubEiRMMHjyY9PR0RzYpImXM6Y+KN2/e/KrvFr0WGgL1LBoC9Txu9ai4B7y+QkR+w+kh8d9OTBHxDA7pk4iNjf3DMLBarVy6dMkRTYqIgzgkJAYPHuyIw4qICzgkJPRN5CI3D81sEhFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDJqvVanV1ESLivnQlISKGFBIiYkghISKGFBIiYkghISKGFBIiYkghISKGFBIiYkghISKGFBJl6OjRo9x1111ERkYSGRlJREQE7du3Jzk5md27dzNq1CjD/UeMGMEXX3zxu+W7du1i4sSJjipb/mPLli3ExsZe8/bJycm0a9eOOXPmMHLkSI4dO+bA6lzH4uoCbjZBQUEsW7bM9jkrK4vw8HAee+wx3njjjT91zB9//JHTp0+XVYlSRpYtW8acOXOoXbs27du3Z9CgQa4uySF0JeFgp06dwmq1kpGRYfsrlZmZSdeuXYmMjGTs2LF06tTJtv26deuIjo7m4YcfZuHCheTl5ZGcnMzatWt57733XHUa5VpKSgpRUVE88cQTJCUlYbVaSUhIICsri0GDBpGSkkJ2djb9+/fn7Nmzri63zOlKooxlZ2cTGRnJpUuXOHv2LHfffTfTp0/Hx8fHts2IESMYOnQobdu2Ze7cuZSUlNjWFRYWsnjxYvbv30/v3r3p0aMHQ4YMYevWrTz33HOuOKVybf369WRkZLBkyRJMJhMvvfQSy5cvJzExkY0bN5KSkkJISAifffYZKSkpVKlSxdUllzldSZSx/95ufPnll0RGRmK1WnnggQds68+dO8exY8do27YtAN26dbtq/w4dOmAymahfv/5N+VfJ02zevJldu3bRtWtXoqKiyMjI4Mcff3R1WU6lKwkH8fLyIj4+ni5dujBr1iyaNGkCgNlsxujpfLPZDIDJZHJKnWKspKSEPn360LdvXwDy8vJs/43KC11JOJDFYiE+Pp4ZM2aQk5MDQGBgIDVr1iQ9PR2A1NRUu8cxm80UFxc7tFb5Y61atWLZsmXk5+dTXFzMoEGDWLly5e+2M5vNV9023kwUEg7Wpk0bmjVrxrRp02zLkpKSmDFjBlFRUezatQs/Pz/DYzRp0oTvvvuOSZMmObrccm/btm00a9bM9m/dunV07tyZmJgYHn/8cRo0aEBUVNTv9mvXrh39+/fnyJEjLqjasfRmKheYPn06MTExBAUFsWrVKlJTU3nnnXdcXZbIH1KfhAsEBwfTr18/LBYLlSpV+tPzJ0ScQVcSImJIfRIiYkghISKGFBIiYkghUU7169ePM2fOOOz4oaGhdo8fGxvLihUrruu4X3zxBQMGDLiR0uQ6KSTKqU2bNrm6BPEQColyaOTIkQD06dOHEydO0L59e4YNG8bf/vY3Vq9eTfv27dm9e7dt+99+3rFjBz179iQqKopu3bqRlpZm2NaFCxeIj4+nR48ehIeH07VrVw4ePGhbv3r1arp27cqjjz561VOu19uOOI7mSZRD48eP54svvmDevHlUrVoVgPr16zN16lTb+j+Sm5vLyJEjmTVrFiEhIWRlZRETE0NoaCjBwcF/uM/69eupVKkSCxcuBCAhIYEFCxYwZswYAPLz81m0aBEFBQV0796dRo0a0bRp01LbEedTSAgA9913n91tdu7cyalTp656uYrJZGLfvn2lhsQjjzxCzZo1+eijjzh8+DBbt26lWbNmtvXR0dFYLBYCAgIIDw/n66+/Bii1HXE+hYQA4O/vf9Xn386xKywsBK48EVm3bl0WL15sW5eVlWW7Gvkjn3zyCYsWLeLJJ58kIiKCypUrc/ToUdv63z5RabVasVgshu1cywNxUrbUJ1FOGT1ZWrVqVTIyMoAr7308deoUAE2bNuXw4cP8+9//BmDPnj2Eh4eTlZVVajsbN24kKiqK7t27U7t2bdauXXvV05JLly7FarWSm5vLv/71Lx566KE/1Y44jq4kyqlHHnmE2NjYP3ywLC4ujtdee42FCxfSuHFjGjduDFwJj+TkZJKSkrh06RJWq5WkpCRCQkJKbadfv34kJCSwZMkS4ErQZGZm2tYHBgbStWtXCgoK6NWrF61atQIotZ2tW7eW5a9BroGe3RARQ7rdEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMfR/ZSGq4qinT24AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(y_test_lem, mnb_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Right', 'Left'], yticklabels=['Right', 'Left'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([13945,  6183,  7323,  8678,  9725,   142,  8214, 10630, 13450,\n",
       "             5728,\n",
       "            ...\n",
       "            17422,  5401,  8138, 14548, 12747, 16922, 17135,  1454,  1501,\n",
       "             9295],\n",
       "           dtype='int64', length=6573)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_lem.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-378-e4180468063b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test_lem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_test_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'right'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1652\u001b[0m             \u001b[0;31m# just raising\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1655\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                     \u001b[0;34m\"is no longer supported, see \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
     ]
    }
   ],
   "source": [
    "test = comments_df.loc[y_test_lem.index]\n",
    "test['pred'] = rf_test_preds\n",
    "test['pred'] = test['pred'].apply(lambda x: 'right' if x == 1 else 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-379-c79d526ba28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mguessed_right_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment_class\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mguessed_right_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mguessed_left_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment_class\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mguessed_left_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "guessed_right_wrong = test[(test.comment_class != test.pred) & (test.pred == 'right')]\n",
    "guessed_right_wrong.reset_index(drop=True, inplace=True)\n",
    "\n",
    "guessed_left_wrong = test[(test.comment_class != test.pred) & (test.pred == 'left')]\n",
    "guessed_left_wrong.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUESSED RIGHT BUT WE WERE WRONG\n",
      "_______________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'guessed_right_wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-380-d7cd6e846f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_______________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguessed_right_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guessed_right_wrong' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"GUESSED RIGHT BUT WE WERE WRONG\")\n",
    "print(\"_______________________________\")\n",
    "for i in range(0,50):\n",
    "    print(guessed_right_wrong.iloc[i].body)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUESSED LEFT BUT WE WERE WRONG\n",
      "______________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'guessed_left_wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-381-4c1d1ba7a9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"______________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguessed_left_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guessed_left_wrong' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"GUESSED LEFT BUT WE WERE WRONG\")\n",
    "print(\"______________________________\")\n",
    "for i in range(0,50):\n",
    "    print(guessed_left_wrong.iloc[i].body)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
