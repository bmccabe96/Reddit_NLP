{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note, only using comments_df for now until we figure out if it is worth it to use the posts_df as well somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Import Packages, define functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import mysql.connector\n",
    "# some_file.py\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/brianmccabe/DataScience/Flatiron/mod4/Reddit_NLP/Scripts')\n",
    "#import config\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "import scipy\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can define a function that removes stopwords \n",
    "def process_comment(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_percentage(comment):\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    cap_count = 0\n",
    "    for item in tokens:\n",
    "        if item.isupper():\n",
    "            cap_count += 1\n",
    "    return cap_count/len(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_profanity(comment):\n",
    "    profane = pd.read_csv(\"/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/profane_words.csv\", header=None)\n",
    "    profane = list(profane.loc[:,0])\n",
    "    count = 0\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    for word in tokens:\n",
    "        if word in profane:\n",
    "            count += 1\n",
    "    return count/len(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stopwords and punctuations\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords += list(string.punctuation)\n",
    "stopwords += [\"n't\", \"' '\", \"'re'\",\"”\",\"``\",\"“\",\"''\",\"’\",\"'s\",\"'re\",\"http\",\"https\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.read_csv('/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/posts_df.csv', index_col=0)\n",
    "comments_df = pd.read_csv('/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/comments_df_(1).csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151515"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df.columns = ['id_num', 'post_title', 'post_author', 'post_upvote_ratio', 'post_id', 'post_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.columns = ['id_num', 'body', 'comment_id', 'parent_id', 'post_id', 'author', 'score', 'comment_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = '\\w+_(\\w+)'\n",
    "p = re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.post_id = comments_df.post_id.apply(lambda x: p.findall(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RID OF NEGATIVE SCORES (a negative score in a conservative subreddit could be a brigader for example)\n",
    "comments_df = comments_df[comments_df.score > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = comments_df[['body', 'comment_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "right    17116\n",
       "left     15773\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecmccabe/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "leaning_map = {'right': 1, 'left': 0}\n",
    "df.comment_class = df.comment_class.map(leaning_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-67af6b43cc2d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_len'] = df['body'].map(lambda x: len(x))\n"
     ]
    }
   ],
   "source": [
    "df['text_len'] = df['body'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.text_len >= 100]\n",
    "df.drop('text_len', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9389\n",
       "1    9184\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9389\n",
       "0    9389\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "right = df[df.comment_class == 1]\n",
    "left = df[df.comment_class == 0]\n",
    "\n",
    "right_upsampled = resample(right,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(left), # match number in majority class\n",
    "                          random_state=42) \n",
    "df = pd.concat([left, right_upsampled])\n",
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['body']\n",
    "y = df['comment_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        As a Lesbian, I get a lot of backlash when peo...\n",
       "1        “*These are radical islamic terrorists and she...\n",
       "2        I hope Gov. Whitmer still has all that extra s...\n",
       "3        She's not wrong. I hope this woman goes places...\n",
       "4        The Orange Tweeter's irresponsible actions hav...\n",
       "                               ...                        \n",
       "18773    Oh heavens, she was pointed and laughed at.  S...\n",
       "18774    Atheist here and this bothers me.  Believe me ...\n",
       "18775    The good news is, if Biden wins and institutes...\n",
       "18776    Not exactly shocking that communities will ban...\n",
       "18777    Because I’m a woman living alone who is in a c...\n",
       "Name: body, Length: 18778, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pronouns(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def count_pronouns(self, comment):\n",
    "        comment = comment.lower()\n",
    "        tokens = nltk.word_tokenize(comment)\n",
    "\n",
    "        pos_tags = [i[1] for i in nltk.pos_tag(tokens)]\n",
    "        count = 0\n",
    "        pronouns = ['PRP','PRP$','WP','WP$']\n",
    "        for pos in pos_tags:\n",
    "            if pos in pronouns:\n",
    "                count += 1\n",
    "\n",
    "        return count / len(tokens)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return pd.Series(X).apply(self.count_pronouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = Pronouns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pronouns()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouns.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns_vector = pronouns.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.106195\n",
       "1        0.048780\n",
       "2        0.058824\n",
       "3        0.107143\n",
       "4        0.029412\n",
       "           ...   \n",
       "18773    0.094340\n",
       "18774    0.054545\n",
       "18775    0.000000\n",
       "18776    0.037037\n",
       "18777    0.037037\n",
       "Name: body, Length: 18778, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouns_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_train, pro_test, y_train, y_test = train_test_split(pronouns_vector, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capitalization_Normalizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def capital_percentage(self, lst):\n",
    "        return sum([1 if x.isupper() else 0 for x in lst]) / len(lst)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        tokens = pd.Series(X).apply(nltk.word_tokenize)\n",
    "        return tokens.apply(self.capital_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals = Capitalization_Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capitalization_Normalizer()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitals.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals_vector = capitals.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_train, cap_test, y_train, y_test = train_test_split(capitals_vector, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Profanity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "profanity_count = X.apply(check_profanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_train, prof_test, y_train, y_test = train_test_split(profanity_count, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Done with new features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply above function to data\n",
    "\n",
    "processed_comments = list(map(process_comment, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run these if Lemma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with lemmatized output\n",
    "lemmatized_output = []\n",
    "\n",
    "for comment in processed_comments:\n",
    "    lemmed = ' '.join([lemmatizer.lemmatize(w) for w in comment])\n",
    "    lemmatized_output.append(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this to 'lemmatized_output' if you are including lemma (see above)\n",
    "X_lem = lemmatized_output\n",
    "\n",
    "y_lem = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "        self.dim = 300\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Doc.vector defaults to an average of the token vectors.\n",
    "        # https://spacy.io/api/doc#vector\n",
    "        \n",
    "        return [self.nlp(text).vector for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# embeddings_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "#         (\"reduce_dim\", TruncatedSVD(50)),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )\n",
    "# embeddings_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = embeddings_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868656</td>\n",
       "      <td>0.942511</td>\n",
       "      <td>0.904078</td>\n",
       "      <td>3305.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.936391</td>\n",
       "      <td>0.855875</td>\n",
       "      <td>0.894325</td>\n",
       "      <td>3268.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.899437</td>\n",
       "      <td>0.899437</td>\n",
       "      <td>0.899437</td>\n",
       "      <td>0.899437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.902523</td>\n",
       "      <td>0.899193</td>\n",
       "      <td>0.899201</td>\n",
       "      <td>6573.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.902333</td>\n",
       "      <td>0.899437</td>\n",
       "      <td>0.899229</td>\n",
       "      <td>6573.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.868656  0.942511  0.904078  3305.000000\n",
       "1              0.936391  0.855875  0.894325  3268.000000\n",
       "accuracy       0.899437  0.899437  0.899437     0.899437\n",
       "macro avg      0.902523  0.899193  0.899201  6573.000000\n",
       "weighted avg   0.902333  0.899437  0.899229  6573.000000"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# tfidf_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"tfidf\", TfidfVectorizer()),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# tfidf_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = tfidf_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.925325</td>\n",
       "      <td>0.948563</td>\n",
       "      <td>0.936800</td>\n",
       "      <td>3305.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.946625</td>\n",
       "      <td>0.922583</td>\n",
       "      <td>0.934449</td>\n",
       "      <td>3268.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.935646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.935975</td>\n",
       "      <td>0.935573</td>\n",
       "      <td>0.935624</td>\n",
       "      <td>6573.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.935915</td>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.935631</td>\n",
       "      <td>6573.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.925325  0.948563  0.936800  3305.000000\n",
       "1              0.946625  0.922583  0.934449  3268.000000\n",
       "accuracy       0.935646  0.935646  0.935646     0.935646\n",
       "macro avg      0.935975  0.935573  0.935624  6573.000000\n",
       "weighted avg   0.935915  0.935646  0.935631  6573.000000"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # individual pipelines minus the estimator step: \n",
    "# tfidf_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"tfidf\", TfidfVectorizer()),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# embeddings_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "#         (\"reduce_dim\", TruncatedSVD(50)),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_features = FeatureUnion(\n",
    "#     transformer_list=[\n",
    "#         (\"tfidf\", tfidf_pipeline),\n",
    "#         (\"embeddings\", embeddings_pipeline),\n",
    "#         #(try adding a pipeline that is just the dense columns)\n",
    "#     ]\n",
    "# )\n",
    "# final_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"combined_features\", combined_features),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# final_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = final_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898741</td>\n",
       "      <td>0.972163</td>\n",
       "      <td>0.934012</td>\n",
       "      <td>3305.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.969313</td>\n",
       "      <td>0.889229</td>\n",
       "      <td>0.927545</td>\n",
       "      <td>3268.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.930930</td>\n",
       "      <td>0.930930</td>\n",
       "      <td>0.930930</td>\n",
       "      <td>0.93093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.934027</td>\n",
       "      <td>0.930696</td>\n",
       "      <td>0.930779</td>\n",
       "      <td>6573.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.933828</td>\n",
       "      <td>0.930930</td>\n",
       "      <td>0.930797</td>\n",
       "      <td>6573.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.898741  0.972163  0.934012  3305.00000\n",
       "1              0.969313  0.889229  0.927545  3268.00000\n",
       "accuracy       0.930930  0.930930  0.930930     0.93093\n",
       "macro avg      0.934027  0.930696  0.930779  6573.00000\n",
       "weighted avg   0.933828  0.930930  0.930797  6573.00000"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining Sparse with Dense**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_input(pro_tr = None, pro_te = None, cap_tr = None, cap_te = None, \n",
    "                     prof_tr = None, prof_te = None):\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "    tfidf_data_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "    tfidf_data_test_lem = tfidf.transform(X_test_lem)\n",
    "    \n",
    "    \n",
    "    tfidf_data_train_lem = pd.DataFrame(tfidf_data_train_lem.toarray(), columns=tfidf.vocabulary_.keys())\n",
    "\n",
    "    tfidf_data_test_lem = pd.DataFrame(tfidf_data_test_lem.toarray(), columns=tfidf.vocabulary_.keys())\n",
    "    \n",
    "    print(\"Finished Part 1\")\n",
    "\n",
    "     \n",
    "    if str(type(pro_tr)) != str(type(None)) and str(type(pro_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xpronouns'] = pro_tr\n",
    "        tfidf_data_test_lem['Xpronouns'] = pro_te\n",
    "        print('finished pronoun_test')\n",
    "        \n",
    "    if str(type(cap_tr)) != str(type(None)) and str(type(cap_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xcapitals'] = cap_tr\n",
    "        tfidf_data_test_lem['Xcapitals'] = cap_te\n",
    "        print('finished capital_test')\n",
    "\n",
    "        \n",
    "    if str(type(prof_tr)) != str(type(None)) and str(type(prof_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xprofanity'] = prof_tr\n",
    "        tfidf_data_test_lem['Xprofanity'] = prof_te\n",
    "        print('finished profanity_test')\n",
    "\n",
    "        \n",
    "    train_columns = tfidf_data_train_lem.columns\n",
    "    \n",
    "    tfidf_data_train_lem = scipy.sparse.csr_matrix(tfidf_data_train_lem)\n",
    "    \n",
    "    print(\"Finished train sparsing\")\n",
    "    \n",
    "    tfidf_data_test_lem = scipy.sparse.csr_matrix(tfidf_data_test_lem)\n",
    "    \n",
    "    print(\"Finished test sparsing\")\n",
    "\n",
    "    \n",
    "    return tfidf_data_train_lem, tfidf_data_test_lem, train_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dif dataframes to test models with, 1 with each feature appended to Tf IDF and one with all 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished pronoun_test\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-a2cf0fcc8b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpro_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpro_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpro_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpro_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpro_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpro_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpro_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprof_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprof_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprof_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprof_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprof_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcap_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-e7797bba698d>\u001b[0m in \u001b[0;36mclassifier_input\u001b[0;34m(pro_tr, pro_te, cap_tr, cap_te, prof_tr, prof_te)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtrain_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_data_train_lem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtfidf_data_train_lem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_data_train_lem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished train sparsing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     86\u001b[0m                                  \"\".format(self.format))\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Read matrix dimensions given, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    189\u001b[0m                                          (shape, self._shape))\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_canonical_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             raise ValueError(\"The truth value of an array with more than one \"\n\u001b[0m\u001b[1;32m    288\u001b[0m                              \"element is ambiguous. Use a.any() or a.all().\")\n\u001b[1;32m    289\u001b[0m     \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "pro_train, pro_test, pro_columns = classifier_input(pro_tr = pro_train, pro_te = pro_test)\n",
    "\n",
    "prof_train, prof_test, prof_columns = classifier_input(prof_tr = prof_train, prof_te = prof_test)\n",
    "\n",
    "cap_train, cap_test, cap_columns = classifier_input(cap_tr = cap_train, cap_te = cap_test)\n",
    "\n",
    "combined_train, combined_test, combined_columns = classifier_input(pro_tr = pro_train, pro_te = pro_test,\n",
    "                                                                  prof_tr = prof_train, prof_te = prof_test,\n",
    "                                                                  cap_tr = cap_train, cap_te = cap_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Pronoun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.9407\n",
      "\n",
      "F1 Score: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_pro = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_pro.fit(pro_train, y_train_lem)\n",
    "rf_test_preds = rfc_pro.predict(pro_test)\n",
    "\n",
    "rf_pro_acc_score_lem = accuracy_score(y_test_lem, rf_test_preds)\n",
    "rf_pro_f1_score_lem = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(rf_pro_acc_score_lem))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(rf_pro_f1_score_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(pro_columns, rfc_pro.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.045142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.028265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.008079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.007827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>street</td>\n",
       "      <td>0.007068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xpronouns</td>\n",
       "      <td>0.005677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vu</td>\n",
       "      <td>0.005470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>biggly</td>\n",
       "      <td>0.005450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amend</td>\n",
       "      <td>0.005352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ojelr5pxgdu</td>\n",
       "      <td>0.004591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0          hoa    0.045142\n",
       "1  underpaying    0.028265\n",
       "2       jurist    0.008079\n",
       "3         bees    0.007827\n",
       "4       street    0.007068\n",
       "5    Xpronouns    0.005677\n",
       "6           vu    0.005470\n",
       "7       biggly    0.005450\n",
       "8        amend    0.005352\n",
       "9  ojelr5pxgdu    0.004591"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_test_lem, rf_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Right', 'Left'], yticklabels=['Right', 'Left'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with Profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Profanity\n",
      "Testing Accuracy: 0.9335\n",
      "\n",
      "F1 Score: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_prof = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_prof.fit(prof_train, y_train_lem)\n",
    "rf_test_preds = rfc_prof.predict(prof_test)\n",
    "\n",
    "rf_prof_acc_score_lem = accuracy_score(y_test_lem, rf_test_preds)\n",
    "rf_prof_f1_score_lem = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Profanity')\n",
    "print(\"Testing Accuracy: {:.4}\".format(rf_prof_acc_score_lem))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(rf_prof_f1_score_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(prof_columns, rfc_prof.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.028132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xprofanity</td>\n",
       "      <td>0.011027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.008421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.008107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>street</td>\n",
       "      <td>0.006794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>biggly</td>\n",
       "      <td>0.005490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vu</td>\n",
       "      <td>0.005379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amend</td>\n",
       "      <td>0.005196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ojelr5pxgdu</td>\n",
       "      <td>0.004517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0          hoa    0.041700\n",
       "1  underpaying    0.028132\n",
       "2   Xprofanity    0.011027\n",
       "3         bees    0.008421\n",
       "4       jurist    0.008107\n",
       "5       street    0.006794\n",
       "6       biggly    0.005490\n",
       "7           vu    0.005379\n",
       "8        amend    0.005196\n",
       "9  ojelr5pxgdu    0.004517"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's interesting that we have a lower accuracy with this model, yet our newly added feature ranks as higher importance than pronouns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with Capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9367\n",
      "\n",
      "F1 Score: 0.9355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_cap = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_cap.fit(cap_train, y_train_lem)\n",
    "rf_test_preds = rfc_cap.predict(cap_test)\n",
    "\n",
    "rf_cap_acc_score_lem = accuracy_score(y_test_lem, rf_test_preds)\n",
    "rf_cap_f1_score_lem = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(rf_cap_acc_score_lem))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(rf_cap_f1_score_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(cap_columns, rfc_cap.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.044085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.027164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.008479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.008161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>street</td>\n",
       "      <td>0.007162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xcapitals</td>\n",
       "      <td>0.006070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>biggly</td>\n",
       "      <td>0.005689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vu</td>\n",
       "      <td>0.005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amend</td>\n",
       "      <td>0.005305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ojelr5pxgdu</td>\n",
       "      <td>0.004661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0          hoa    0.044085\n",
       "1  underpaying    0.027164\n",
       "2         bees    0.008479\n",
       "3       jurist    0.008161\n",
       "4       street    0.007162\n",
       "5    Xcapitals    0.006070\n",
       "6       biggly    0.005689\n",
       "7           vu    0.005575\n",
       "8        amend    0.005305\n",
       "9  ojelr5pxgdu    0.004661"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with all 3 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9356\n",
      "\n",
      "F1 Score: 0.9344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_combined = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_combined.fit(combined_train, y_train_lem)\n",
    "rf_test_preds = rfc_combined.predict(combined_test)\n",
    "\n",
    "rf_combined_acc_score_lem = accuracy_score(y_test_lem, rf_test_preds)\n",
    "rf_combined_f1_score_lem = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(rf_combined_acc_score_lem))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(rf_combined_f1_score_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(combined_columns, rfc_combined.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.045395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.028783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.009556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.008504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>street</td>\n",
       "      <td>0.007107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>biggly</td>\n",
       "      <td>0.005330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vu</td>\n",
       "      <td>0.005241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>amend</td>\n",
       "      <td>0.004831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>catastrophic</td>\n",
       "      <td>0.004791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ojelr5pxgdu</td>\n",
       "      <td>0.004788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ackwards</td>\n",
       "      <td>0.004477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fec</td>\n",
       "      <td>0.004103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>anglophone</td>\n",
       "      <td>0.004039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>projects</td>\n",
       "      <td>0.003862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>instability</td>\n",
       "      <td>0.003715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.003524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fashioned</td>\n",
       "      <td>0.003474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dissident</td>\n",
       "      <td>0.003458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>limited</td>\n",
       "      <td>0.003319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hungry</td>\n",
       "      <td>0.003270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>theatre</td>\n",
       "      <td>0.003203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>expected</td>\n",
       "      <td>0.003201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>guardian</td>\n",
       "      <td>0.003187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>indirect</td>\n",
       "      <td>0.003173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cohabitating</td>\n",
       "      <td>0.003117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>handcuff</td>\n",
       "      <td>0.003091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hardening</td>\n",
       "      <td>0.002893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>curious</td>\n",
       "      <td>0.002638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lowe</td>\n",
       "      <td>0.002635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>remorse</td>\n",
       "      <td>0.002626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>submarine</td>\n",
       "      <td>0.002619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>whiteness</td>\n",
       "      <td>0.002597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>silicon</td>\n",
       "      <td>0.002586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lifted</td>\n",
       "      <td>0.002544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>measured</td>\n",
       "      <td>0.002542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pardoned</td>\n",
       "      <td>0.002507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>understandably</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>illusion</td>\n",
       "      <td>0.002409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>easily</td>\n",
       "      <td>0.002308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>enable</td>\n",
       "      <td>0.002289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>informing</td>\n",
       "      <td>0.002247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>oluo</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>nfl</td>\n",
       "      <td>0.002148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>predicted</td>\n",
       "      <td>0.002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>perplexing</td>\n",
       "      <td>0.002143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>taxable</td>\n",
       "      <td>0.002142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>stepmother</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>renter</td>\n",
       "      <td>0.002076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>picking</td>\n",
       "      <td>0.001973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>based</td>\n",
       "      <td>0.001958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance\n",
       "0              hoa    0.045395\n",
       "1      underpaying    0.028783\n",
       "2             bees    0.009556\n",
       "3           jurist    0.008504\n",
       "4           street    0.007107\n",
       "5           biggly    0.005330\n",
       "6               vu    0.005241\n",
       "7            amend    0.004831\n",
       "8     catastrophic    0.004791\n",
       "9      ojelr5pxgdu    0.004788\n",
       "10        ackwards    0.004477\n",
       "11             fec    0.004103\n",
       "12      anglophone    0.004039\n",
       "13        projects    0.003862\n",
       "14     instability    0.003715\n",
       "15         mexican    0.003524\n",
       "16       fashioned    0.003474\n",
       "17       dissident    0.003458\n",
       "18         limited    0.003319\n",
       "19          hungry    0.003270\n",
       "20         theatre    0.003203\n",
       "21        expected    0.003201\n",
       "22        guardian    0.003187\n",
       "23        indirect    0.003173\n",
       "24    cohabitating    0.003117\n",
       "25        handcuff    0.003091\n",
       "26       hardening    0.002893\n",
       "27         curious    0.002638\n",
       "28            lowe    0.002635\n",
       "29         remorse    0.002626\n",
       "30       submarine    0.002619\n",
       "31       whiteness    0.002597\n",
       "32         silicon    0.002586\n",
       "33          lifted    0.002544\n",
       "34        measured    0.002542\n",
       "35        pardoned    0.002507\n",
       "36  understandably    0.002506\n",
       "37        illusion    0.002409\n",
       "38          easily    0.002308\n",
       "39          enable    0.002289\n",
       "40       informing    0.002247\n",
       "41            oluo    0.002188\n",
       "42             nfl    0.002148\n",
       "43       predicted    0.002146\n",
       "44      perplexing    0.002143\n",
       "45         taxable    0.002142\n",
       "46      stepmother    0.002115\n",
       "47          renter    0.002076\n",
       "48         picking    0.001973\n",
       "49           based    0.001958"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Random Forest with Lemmatization Features\n",
      "Testing Accuracy: 0.9356\n",
      "\n",
      "F1 Score: 0.9339\n"
     ]
    }
   ],
   "source": [
    "svc_lemma = SVC(verbose=1)\n",
    "svc_lemma.fit(tfidf_data_train_lem, y_train_lem)\n",
    "rf_test_preds = svc_lemma.predict(tfidf_data_test_lem)\n",
    "\n",
    "rf_acc_score_lem = accuracy_score(y_test_lem, rf_test_preds)\n",
    "rf_f1_score_lem = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features')\n",
    "print(\"Testing Accuracy: {:.4}\".format(rf_acc_score_lem))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(rf_f1_score_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MN Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes model accuracy\n",
      "Testing Accuracy: 0.8801\n",
      "\n",
      "F1 Score: 0.8789\n"
     ]
    }
   ],
   "source": [
    "mnb_lemma = MultinomialNB()\n",
    "mnb_lemma.fit(tfidf_data_train_lem, y_train_lem)\n",
    "mnb_test_preds = mnb_lemma.predict(tfidf_data_test_lem)\n",
    "\n",
    "mnb_acc_score_lem = accuracy_score(y_test_lem, mnb_test_preds)\n",
    "mnb_f1_score_lem = f1_score(y_test_lem, mnb_test_preds)\n",
    "print('Multinomial Naive Bayes model accuracy')\n",
    "print(\"Testing Accuracy: {:.4}\".format(mnb_acc_score_lem))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(mnb_f1_score_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAEJCAYAAACHaNJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdh0lEQVR4nO3deVRV9d7H8ffhHAYRvGpFimjXKRzK1FK0Qc2JbkWIIt5rommlljncJNJUKrQ01FQyS8qxrBzqUXlW1yFFHDK9aqaUimmaI4gDJIoMnucP7z3lU+yjyZnk81rLtTh7+n03rT7s/fv99j4mq9VqRUSkFF6uLkBE3JtCQkQMKSRExJBCQkQMKSRExJBCQkQMWVxdwLUoyjno6hLkOgSEtHV1CXKdLhUcKXWdriRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJBCQkQMKSRExJDF1QXcTFJXrmXOJ0swYcLPz5eRwwZSs0Z1EidOZ9/+A1So4EeXRzvxZPdIAHbv2cdb01K4eLGAy5cv069XdyLC2wOwbedu3n53FgWFhQRWrMi4US9Ss0Z1V55eufFERDizZ0/l1tsa4uXlRdJbY+jcuR0Wi4UpU2bywYcfA9C2bWvemjAGi8XC6TNniYt7jd2797i4+rKnkCgjPx0+yuR3P2Tx7OncdmtV1n+9lWGjxtGyWRP8/f1YtmAmly9fZsiIRGoEV6Pt/S3556g3GDvyn7Ru0YyT2aeI6TuYJo1C8fX1YejIsXww9U0ahdbjo0VLGTf5XWa+Pc7Vp3nTq1f3r0yYMBqTyQTAs8/0on79OjRr3pHAwADWpy/l250ZZGYeYOFnKfyj50DS0jYRemddliyZxb33daawsNDFZ1G2HHq7MXPmzN8te/vttx3ZpMv4+Hjz+ohh3HZrVQAaN7yTnNNnydibSUR4B8xmM97e3rS5vyWr0zZSWFjEc32fpHWLZgBUC7qNKpX/QlZ2DqvTNvJgq/toFFoPgJjIR3l56ACXnVt5UaGCH3PmJBMfn2hbFhkZzrz5iygpKeHcuVwWLV5Oz39EUa9ebXLzfiEtbRMA+zIPkJd3nlatmruqfIdxyJXEpEmTOH36NGvXruXQoUO25cXFxezatYsXX3zREc26VI3qt1Oj+u0AWK1WkpJTePjBMAICKpK6cg3NmjSiqLCI1es2YbGY8fX1oVtEuG3/xcu+JP/iRZrc1YCVaRvwr+BHXMJ4Dv18lOq3BxE/pL+rTq3cePfdCXw4awG7M369ZQgJCebo0eO2z8eOneDuuxqyf/9BKvr707FjG776aj333nsPjRrdSbVqt7uidIdySEh07tyZAwcO8M0339CyZUvbcrPZzKBBgxzRpNu4cLGA0W9M5mTWKd7/z+3BpOkf0v2pF7j1liq0btGMnRk/XLXPhx8t4uPFS3l/8jj8fH0pLi5h3aYtzJ8xkTtq1uDjxcsY9so4Pp/3ritOqVwY0L83xcUlzJu3kDvuCLEt9/Lywmq12j6bTCZKSkr45ZfzdI95htdfj2f8m6PYuHEL69ZtuuluNcBBIdGkSROaNGlCx44dCQwMdEQTbunEyWwGvfwade6oyezpb+Hn68uJk9kMH/Q0f6l05feQMu8zatUIBqCwsJBRb7zNgUM/s2DmFNuVyG23VqXZ3Y24o2YNALo+Hs6Eqe9TcOkSfr6+rjm5m1xsbHf8/SuwdcsKfHy8qVDBj61bVnD02AmqV69m26569ds5duwkJpOJ8+fz6dw5xrYuY3c6Bw4cckH1juXQPokVK1bQunVrGjZsSMOGDWnQoAENGzZ0ZJMuk59/gb6DX6Zj2weYlDjS9j/zwqVfMv2DjwDIOXOWL/53JY92bgfAiMSJnM+/wMfvv20LCICObe7n290/cPT4SQC+St9Evdp3KCAc6MGHImh+b0dahj1CZJc+XLxYQMuwR1i+bAVP9YnBbDbzl79UIqb7EyxPXYnVamXZ0vk0b94EgOjoCAoKLml043q99957zJ8/n/r16zuyGbfwyeepHD+ZzZr0r1mT/rVt+TtvJTBh6ky69BqI1Wpl0DOx3N0wlJ0Ze1iVtpG/1qxB7MDhtu1ffL4fD4Tdy+jhgxg6cizFxcVUqhTA5HGvuOK0yr2ZKR9Rp84dbPv3Snx8fPjwwwVs2PANAH2eGsx7M97Cx8ebkyez6R7zjIurdQyT9bc3XGWse/fuLF68+IaPU5RzsAyqEWcJCGnr6hLkOl0qOFLqOodcSSxduhSA4OBgnnvuOTp06IDF8mtTXbp0cUSzIuIADgmJLVu2AODv74+/vz/bt2+/ar1CQsRzOPR2o6zodsOz6HbD8zj9duO/OnfuTElJie2zyWTCz8+POnXq8PLLL1OjRg1HNi8iZcChIdGmTRtCQkKIjo4GYPny5ezevZv27dszatQo5s6d68jmRaQMOHSexPbt23nqqacICAggICCAnj17sm/fPjp16kRubq4jmxaRMuLQkPDy8mLDhg22zxs2bMDHx4ecnByKi4sd2bSIlBGHdlxmZmYyYsQIjh07BkCtWrWYMGECK1asIDg4mKioqGs6jjouPYs6Lj2PUcelU0Y3cnNzMZvNBAQE/Kn9FRKeRSHheZw+ujFmzBjGjh1LbGys7eUd/2UymZg3b54jmhURB3BISPTo0YODBw8SExPD7bf/+uBSTk4O06ZNc0STIuIgDum4TEtLo1u3biQkJFBcXEzLli3ZtWsXo0ePJiQkxP4BRMRtlNon8f333xvu2Lhx41LXdejQgU8//ZTs7GySk5O5fPkyWVlZxMfH89BDD113keqT8Czqk/A8f6pPYvDgwaXuZDKZWLNmTanrK1asSFBQEEFBQezatYsuXbowc+ZMzGbzNZYsIu6i1JBYu3btnz6ol9evdzFVqlRhxIgRf/pYIuJadvsk8vPzSUxMpE+fPpw7d46EhATy8/MN9/ntiIafn9+NVykiLmN3dGPcuHEEBQVx+vRpfH19OX/+PAkJCUyePLnUffbv30+HDh0AyMrKsv1stVrt3qqIiHuxGxJ79uxh/PjxpKenU6FCBSZNmsTjjz9uuM/KlSvLrEARcS27IfHb/gWAkpKS3y37//QIuMjNw25ItGjRgokTJ1JQUMCGDRtYsGABYWFhzqhNRNyA3Y7LuLg4/P39CQwMZMqUKYSGhhIfH++M2kTEDVzzA17nz5/H29sbXxd894MmU3kWTabyPEaTqexeSRw6dIiYmBjCwsK499576d27NydOnCjTAkXEfdkNiYSEBKKjo9m5cyc7duygU6dOjB492hm1iYgbsBsSeXl5xMTE4O3tjY+PD7GxseTk5DijNhFxA3ZDolatWnz33Xe2z3v37qVWrVoOLUpE3EepQ6ARERHAlWnZPXv2JDQ0FC8vL/bu3UvdunWdVqCIuFapITFmzBhn1iEibqrUkGjZsqXt53PnznHx4kWsVislJSX8/PPPTilORFzP7ozLadOmkZKSAoDZbKaoqIh69eqRmprq8OJExPXsdlwuW7aMtLQ0wsPDWbVqFePHj6devXrOqE1E3IDdkKhatSpBQUHUqVOHvXv30qVLFzIzM51Rm4i4AbshYbFY+Pnnn6lTpw7btm2juLiYS5cuOaM2EXEDdkNiwIABjBkzhnbt2rFq1SratWunp0BFypHr+gavixcvcvjwYRo0aODImn5HD3h5Fj3g5Xn+1Nuyx40bZ3hQPb8hUj6UGhKVK1d2Zh0i4qac8oXBN0q3G55Ftxue54beJyEi5ZtCQkQMKSRExFCpHZfTp0833PGFF14o82JExP2UGhJnz54F4ODBg/z000907NgRi8XCmjVrCA0NdVqBIuJadkc3evfuzdSpU6latSoAubm5PP/88yxYsMApBYJGNzyNRjc8zw2Nbpw6dcoWEACVKlXi9OnTZVOZiLg9u++TCA0NZeTIkURGRmK1WlmyZAn33HOPM2oTETdg93bj/PnzJCcns3nzZgDatGnD4MGD8fPzc0qBoNsNT6PbDc9jdLtxTTMuCwoKOHToEHfeeSeXLl2iQoUKZVqgPQoJz6KQ8Dw31Cexc+dOOnbsyMCBA8nOzqZdu3bs2LGjTAsUEfdl90qiZ8+eJCYmEhcXx9KlS0lPTyc5OZnPP//cWTVi8anhtLbkxl048KWrS5Dr5FOz9H5Gu1cSBQUFV73Tsm3btpSUlJRNZSLi9q7p9XW5ubmYTCbgyuQqESk/7A6BDhw4kF69epGTk8OLL77Ipk2bSExMdEZtIuIGrml04/Dhw2zatInLly/TunVrp3/Nn/okPIv6JDzPDfVJvPLKK9xxxx307NmTXr16UbduXYYMGVKmBYqI+yr1duPVV18lKyuL7du3c+bMGdvy4uJijhwpfUxVRG4upYZEdHQ0+/fvZ9++fYSHh9uWm81mmjZt6pTiRMT17PZJnDx5kiNHjtCiRQvOnTvHtm3b6Nixo7PqA9Qn4WnUJ+F5bqhP4tNPPyU5ORm4MmciJSWFGTNmlF11IuLW7IbEmjVrmD17NgDVqlXj448/5ssv9ZdCpLywGxJFRUV4e3vbPnt7e9smVonIzc/uZKrmzZszfPhwoqOjMZlMLF26VO+TEClH7HZcXrhwgWnTprF582YsFgutW7fmhRdecOrj4uq49CzquPQ8Rh2XHvENXgoJz6KQ8DxGIVHq7cbQoUOZNm0aERERf7g+NTX1xisTEbdXakg8++yzAIwZM8ZpxYiI+yk1JKpWrcrx48cJCQlxZj0i4mZKDYnHHnsMk8mE1WqloKCAihUrYjabycvL45ZbbmHjxo3OrFNEXKTUkPj2228BSEhIICwsjMceewy4Mrnqq6++ck51IuJydidTZWRk2AICoEOHDuzdu9ehRYmI+7AbEpcvX2bLli22z+vXr9eMS5FyxO6My9GjRzNs2DC8vb2xWq1YrVbeffddZ9QmIm7gmiZTFRUVkZmZCVz52j+LxW62lClNpvIsmkzleW7oUfH8/HzGjx9PUlISNWrUIDExkfz8/DItUETcl92QGDduHIGBgZw+fRpfX1/Onz9PQkKCM2oTETdgNyT27NnDP//5TywWCxUqVGDSpEns2bPHGbWJiBuwGxJeXldvUlJS8rtlInLzstsD2aJFCyZOnEhBQQEbNmxgwYIFhIWFOaM2EXEDdi8J4uLi8Pf3JzAwkClTphAaGkp8fLwzahMRN2B3CHTy5MkMHz7cWfX8IQ2BehYNgXqeGxoCXbduXVnWIiIexm6fREhICP369aN58+ZUrFjRtrxv374OLUxE3IPdkKhcuTIAx44dc3gxIuJ+rvkdl7m5uZjNZgICAhxd0++oT8KzqE/C89xQn8TBgwfp1q0b999/P2FhYfTq1Yvjx4+XaYEi4r7shsTIkSPp3r07O3fu5NtvvyU8PJxRo0Y5ozYRcQN2Q+LixYv8/e9/x9vbGx8fH2JjY8nJyXFGbSLiBuyGRJ06ddixY4ftc2Zmpl6OK1KO2B3dOH78OLGxsbb3SPzwww/cdttttu/j0PdviNzc7IZEXFycM+oQETdlNyRatmzpjDpExE3pmW8RMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDzv2+vnLm+eeeYsCA3litVg4ePMyAgS8x/Z3x1K37V9s2tf9ak/UbviGqa1/atb2fpKQELBYzZ06f48W4V9m16wfXnUA5kPrVeuYuSsVkAj9fX0YO6kuDerV5851ZbPvP7/6hsGYM7x+LyWRi3eZtjEp6l+pBt9qOMW9KIv4V/HhnzkJWpn9NBT9fmjYK5aXneuPr4+OqUysz1/zSGVfyxJfONG92N4sWfkDz+zqRl/cLSRPGEBAYwPODXrZtc9+997DwsxTaPhxFXt4vHNj/DT3+PoC1aRsJDa3LF5/PoVnzjhQWFrrwTK6fp7x05qcjx+k3/DUWvfcWt91ShfVbdjB26gcMeqoHqavTSXlrDJetl4kdMoa+PZ4gvG1rpn74CRX9/Xi2Z9erjvU/K9JY8D9fMnvya1QKqMj7Hy/hfP4F4gb0dtHZXZ8beumM/Dk7vt1Ng0YPkpf3C76+vgTXqMaZM2dt6729vZk9eyovxr3K0aPHqV+vNrm5v7A2bSMA+/YdIC/vF1q3utdVp3DT8/G28PqLA7ntlioANL6zLjlnz1FYVMTFgksUFhVRVFRMUXExvj7eAOz8YR9bvv2ebv1fos+wBNvVxg/7D9L+/hZUCrjyHtiOD4axev0W15xYGXNoSOTm5v5uWXl6V2ZxcTFPPBHO4Z+28dCDYcydt9C2rl/ff3DieBbLlq0AIHP/QSpW9KdTxzbAlauMxo1CqVY9yCW1lwc1qgXRplVzAKxWKxPfn8fDre+j2986UCmgIh3+PpCHY/pTK/h22rW+D4DKlQKJiejEkplJDH26J8NencTJU6dp0qA+6zZv52xuHpcvX2b56nRO/eaPgidzSEicOHGC48eP8+STT9p+Pn78OEeOHOHpp592RJNua/nylVQLvpvEsW/z5f8uwGQyATB06LO8OX6abbtffjlPt+h+jHh5MNu3raZXr2jS0jZRWFjkqtLLjQsXCxg+dgpHjmXx2vCBvPfRYqpUrkT64g/46tP3yf0ln3mLr7wSYeprcXRu0wqTyUTzuxvQtPGdbN6+i4hObejcphVPxyUSO3QMtWvWwNtyc3T5OeQskpOT2bJlC9nZ2Tz55JO/Nmax0K5dO0c06Xbq1v0r1W6/jU1f/xuAOXM/Y8a7E6hSpTK1agVjMZtJX7/Ztr3JZOJ8/gU6dOpuW/bD9xs4cOCQs0svV05k5fDCmLeoU6sGsya/ip+vD2s2bmXkC33x9rbg7W3hic5tWb3+G6L+1p6Fy1fyzD+ibGFvtYLFYiY37zyPdniQZ3pGAbDz+33UCq7mylMrMw65kggNDWXt2rUMGTKEtWvX2v6tWrWKV155xRFNup3q1YJY8PF73PKf+92ePbuS8f0+zpw5S5uHWpO2btNV21utVlKXzefe5k0A6N79CQoKCjS64UD5Fy7Sd/hrdHywJRNHD8PP98pIRMN6tVm57kqAFxUXs27zNpo0rE/FChX4bNlKvtpwpa9hz/6fyNj3Iw+2aMr3mQcY9uokioqLKS4pYdZnS3msw4MuO7ey5JArifnz5/Pwww+zfPlyIiIi+P8DKMHBwY5o1q1s3LSV8ROSWfPVEoqLSzhx/CTdovsBUK9ebQ4fPvq7fWJ7v8D770/Ex8ebkyey6RZdvm7NnO3TpSs4kX2KNZu2smbTVtvyD5MSeHP6LCL6DsPs5UVYs7vo1yMSs9mL5MR43pw+mxnzF2M2ezFx9DCq/KUS9993D9t2/UC3/i9hvXyZhx9oQWy3x114dmXHIUOgycnJLF++nJMnTxIUdHXHm8lkYs2aNdd1PE8cAi3PPGUIVH5lNATq0HkSr776Kq+//voNH0ch4VkUEp7HZfMkXn/9dVJTU5kyZQoXL15k6dKljmxORBzAoSExadIk0tPTWbVqFcXFxXz++edMmDDBkU2KSBlzaEhs3LiRiRMn4uvrS2BgIHPmzGH9+vWObFJEyphDQ8LL68rh/zumXFhYaFsmIp7BoVPCHnnkEYYNG0Zubi5z585l+fLlPP74zTEsJFJeODQk+vfvz4YNGwgODubEiRMMHjyY9PR0RzYpImXM6Y+KN2/e/KrvFr0WGgL1LBoC9Txu9ai4B7y+QkR+w+kh8d9OTBHxDA7pk4iNjf3DMLBarVy6dMkRTYqIgzgkJAYPHuyIw4qICzgkJPRN5CI3D81sEhFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDJqvVanV1ESLivnQlISKGFBIiYkghISKGFBIiYkghISKGFBIiYkghISKGFBIiYkghISKGFBJl6OjRo9x1111ERkYSGRlJREQE7du3Jzk5md27dzNq1CjD/UeMGMEXX3zxu+W7du1i4sSJjipb/mPLli3ExsZe8/bJycm0a9eOOXPmMHLkSI4dO+bA6lzH4uoCbjZBQUEsW7bM9jkrK4vw8HAee+wx3njjjT91zB9//JHTp0+XVYlSRpYtW8acOXOoXbs27du3Z9CgQa4uySF0JeFgp06dwmq1kpGRYfsrlZmZSdeuXYmMjGTs2LF06tTJtv26deuIjo7m4YcfZuHCheTl5ZGcnMzatWt57733XHUa5VpKSgpRUVE88cQTJCUlYbVaSUhIICsri0GDBpGSkkJ2djb9+/fn7Nmzri63zOlKooxlZ2cTGRnJpUuXOHv2LHfffTfTp0/Hx8fHts2IESMYOnQobdu2Ze7cuZSUlNjWFRYWsnjxYvbv30/v3r3p0aMHQ4YMYevWrTz33HOuOKVybf369WRkZLBkyRJMJhMvvfQSy5cvJzExkY0bN5KSkkJISAifffYZKSkpVKlSxdUllzldSZSx/95ufPnll0RGRmK1WnnggQds68+dO8exY8do27YtAN26dbtq/w4dOmAymahfv/5N+VfJ02zevJldu3bRtWtXoqKiyMjI4Mcff3R1WU6lKwkH8fLyIj4+ni5dujBr1iyaNGkCgNlsxujpfLPZDIDJZHJKnWKspKSEPn360LdvXwDy8vJs/43KC11JOJDFYiE+Pp4ZM2aQk5MDQGBgIDVr1iQ9PR2A1NRUu8cxm80UFxc7tFb5Y61atWLZsmXk5+dTXFzMoEGDWLly5e+2M5vNV9023kwUEg7Wpk0bmjVrxrRp02zLkpKSmDFjBlFRUezatQs/Pz/DYzRp0oTvvvuOSZMmObrccm/btm00a9bM9m/dunV07tyZmJgYHn/8cRo0aEBUVNTv9mvXrh39+/fnyJEjLqjasfRmKheYPn06MTExBAUFsWrVKlJTU3nnnXdcXZbIH1KfhAsEBwfTr18/LBYLlSpV+tPzJ0ScQVcSImJIfRIiYkghISKGFBIiYkghUU7169ePM2fOOOz4oaGhdo8fGxvLihUrruu4X3zxBQMGDLiR0uQ6KSTKqU2bNrm6BPEQColyaOTIkQD06dOHEydO0L59e4YNG8bf/vY3Vq9eTfv27dm9e7dt+99+3rFjBz179iQqKopu3bqRlpZm2NaFCxeIj4+nR48ehIeH07VrVw4ePGhbv3r1arp27cqjjz561VOu19uOOI7mSZRD48eP54svvmDevHlUrVoVgPr16zN16lTb+j+Sm5vLyJEjmTVrFiEhIWRlZRETE0NoaCjBwcF/uM/69eupVKkSCxcuBCAhIYEFCxYwZswYAPLz81m0aBEFBQV0796dRo0a0bRp01LbEedTSAgA9913n91tdu7cyalTp656uYrJZGLfvn2lhsQjjzxCzZo1+eijjzh8+DBbt26lWbNmtvXR0dFYLBYCAgIIDw/n66+/Bii1HXE+hYQA4O/vf9Xn386xKywsBK48EVm3bl0WL15sW5eVlWW7Gvkjn3zyCYsWLeLJJ58kIiKCypUrc/ToUdv63z5RabVasVgshu1cywNxUrbUJ1FOGT1ZWrVqVTIyMoAr7308deoUAE2bNuXw4cP8+9//BmDPnj2Eh4eTlZVVajsbN24kKiqK7t27U7t2bdauXXvV05JLly7FarWSm5vLv/71Lx566KE/1Y44jq4kyqlHHnmE2NjYP3ywLC4ujtdee42FCxfSuHFjGjduDFwJj+TkZJKSkrh06RJWq5WkpCRCQkJKbadfv34kJCSwZMkS4ErQZGZm2tYHBgbStWtXCgoK6NWrF61atQIotZ2tW7eW5a9BroGe3RARQ7rdEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMaSQEBFDCgkRMfR/ZSGq4qinT24AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(y_test_lem, mnb_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Right', 'Left'], yticklabels=['Right', 'Left'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([13945,  6183,  7323,  8678,  9725,   142,  8214, 10630, 13450,\n",
       "             5728,\n",
       "            ...\n",
       "            17422,  5401,  8138, 14548, 12747, 16922, 17135,  1454,  1501,\n",
       "             9295],\n",
       "           dtype='int64', length=6573)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_lem.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-378-e4180468063b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test_lem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_test_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'right'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1652\u001b[0m             \u001b[0;31m# just raising\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1655\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                     \u001b[0;34m\"is no longer supported, see \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
     ]
    }
   ],
   "source": [
    "test = comments_df.loc[y_test_lem.index]\n",
    "test['pred'] = rf_test_preds\n",
    "test['pred'] = test['pred'].apply(lambda x: 'right' if x == 1 else 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-379-c79d526ba28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mguessed_right_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment_class\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mguessed_right_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mguessed_left_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment_class\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mguessed_left_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "guessed_right_wrong = test[(test.comment_class != test.pred) & (test.pred == 'right')]\n",
    "guessed_right_wrong.reset_index(drop=True, inplace=True)\n",
    "\n",
    "guessed_left_wrong = test[(test.comment_class != test.pred) & (test.pred == 'left')]\n",
    "guessed_left_wrong.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUESSED RIGHT BUT WE WERE WRONG\n",
      "_______________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'guessed_right_wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-380-d7cd6e846f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_______________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguessed_right_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guessed_right_wrong' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"GUESSED RIGHT BUT WE WERE WRONG\")\n",
    "print(\"_______________________________\")\n",
    "for i in range(0,50):\n",
    "    print(guessed_right_wrong.iloc[i].body)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUESSED LEFT BUT WE WERE WRONG\n",
      "______________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'guessed_left_wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-381-4c1d1ba7a9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"______________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguessed_left_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guessed_left_wrong' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"GUESSED LEFT BUT WE WERE WRONG\")\n",
    "print(\"______________________________\")\n",
    "for i in range(0,50):\n",
    "    print(guessed_left_wrong.iloc[i].body)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
