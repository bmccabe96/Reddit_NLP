{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note, only using comments_df for now until we figure out if it is worth it to use the posts_df as well somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Import Packages, define functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import mysql.connector\n",
    "# some_file.py\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/brianmccabe/DataScience/Flatiron/mod4/Reddit_NLP/Scripts')\n",
    "#import config\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "import scipy\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stopwords(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    \n",
    "    return (len(tokens) - len(stopwords_removed)) / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can define a function that removes stopwords \n",
    "def process_comment(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_percentage(comment):\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    cap_count = 0\n",
    "    for item in tokens:\n",
    "        if item.isupper():\n",
    "            cap_count += 1\n",
    "    return cap_count/len(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_profanity(comment):\n",
    "    try:\n",
    "        profane = pd.read_csv(\"/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/profane_words.csv\", header=None)\n",
    "    except:\n",
    "        profane = pd.read_csv(\"profane_words.csv\", header=None)\n",
    "\n",
    "    profane = list(profane.loc[:,0])\n",
    "    count = 0\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    for word in tokens:\n",
    "        if word in profane:\n",
    "            count += 1\n",
    "    return count/len(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    \n",
    "    unique_words = len(set(tokens))\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "    return unique_words / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stopwords and punctuations\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords += list(string.punctuation)\n",
    "stopwords += [\"n't\", \"' '\", \"'re'\",\"”\",\"``\",\"“\",\"''\",\"’\",\"'s\",\"'re\",\"http\",\"https\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posts_df = pd.read_csv('/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/posts_df.csv', index_col=0)\n",
    "try:\n",
    "    comments_df = pd.read_csv('/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/comments_df.csv', index_col=0)\n",
    "except:\n",
    "    comments_df = pd.read_csv(\"comments_df.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203837"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posts_df.columns = ['id_num', 'post_title', 'post_author', 'post_upvote_ratio', 'post_id', 'post_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.columns = ['id_num', 'body', 'comment_id', 'parent_id', 'post_id', 'author', 'score', 'comment_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = '\\w+_(\\w+)'\n",
    "p = re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.post_id = comments_df.post_id.apply(lambda x: p.findall(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RID OF NEGATIVE SCORES (a negative score in a conservative subreddit could be a brigader for example)\n",
    "comments_df = comments_df[comments_df.score > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = comments_df[['body', 'comment_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "right    22712\n",
       "left     22397\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecmccabe/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "leaning_map = {'right': 1, 'left': 0}\n",
    "df.comment_class = df.comment_class.map(leaning_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-67af6b43cc2d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_len'] = df['body'].map(lambda x: len(x))\n"
     ]
    }
   ],
   "source": [
    "df['text_len'] = df['body'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.text_len >= 100]\n",
    "df.drop('text_len', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13216\n",
       "1    12177\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13216\n",
       "0    13216\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "right = df[df.comment_class == 1]\n",
    "left = df[df.comment_class == 0]\n",
    "\n",
    "right_upsampled = resample(right,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(left), # match number in majority class\n",
    "                          random_state=42) \n",
    "df = pd.concat([left, right_upsampled])\n",
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>comment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a Lesbian, I get a lot of backlash when peo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“*These are radical islamic terrorists and she...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I hope Gov. Whitmer still has all that extra s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She's not wrong. I hope this woman goes places...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Orange Tweeter's irresponsible actions hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  comment_class\n",
       "0  As a Lesbian, I get a lot of backlash when peo...              0\n",
       "1  “*These are radical islamic terrorists and she...              0\n",
       "2  I hope Gov. Whitmer still has all that extra s...              0\n",
       "3  She's not wrong. I hope this woman goes places...              0\n",
       "4  The Orange Tweeter's irresponsible actions hav...              0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, accuracy, f1]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns = ['model','accuracy','f1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "X = df['body']\n",
    "y = df['comment_class']\n",
    "\n",
    "dummy_cf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_cf.fit(X,y)\n",
    "y_preds = dummy_cf.predict(X)\n",
    "\n",
    "dummy_cf.score(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y, y_preds)\n",
    "f1 = f1_score(y, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  accuracy   f1\n",
       "0  Dummy       0.5  0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'Dummy', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['body']\n",
    "y = df['comment_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        As a Lesbian, I get a lot of backlash when peo...\n",
       "1        “*These are radical islamic terrorists and she...\n",
       "2        I hope Gov. Whitmer still has all that extra s...\n",
       "3        She's not wrong. I hope this woman goes places...\n",
       "4        The Orange Tweeter's irresponsible actions hav...\n",
       "                               ...                        \n",
       "26427    Imagine thinking *this* is the most pressing i...\n",
       "26428    This post is misleading and should either be c...\n",
       "26429    Claiming she’ll use an executive order if cong...\n",
       "26430    Here is a better timeline of events that lead ...\n",
       "26431    Whats bullshit is that this is the first I hav...\n",
       "Name: body, Length: 26432, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count Stopwords Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_count = X.apply(count_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_train, stop_test, y_train, y_test = train_test_split(stopwords_count, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Pronoun Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from Pronouns import Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Pronouns(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "    \n",
    "#     def count_pronouns(self, comment):\n",
    "#         comment = comment.lower()\n",
    "#         tokens = nltk.word_tokenize(comment)\n",
    "\n",
    "#         pos_tags = [i[1] for i in nltk.pos_tag(tokens)]\n",
    "#         count = 0\n",
    "#         pronouns = ['PRP','PRP$','WP','WP$']\n",
    "#         for pos in pos_tags:\n",
    "#             if pos in pronouns:\n",
    "#                 count += 1\n",
    "\n",
    "#         return count / len(tokens)\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         return pd.Series(X).apply(self.count_pronouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = Pronouns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pronouns()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouns.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns_vector = pronouns.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.106195\n",
       "1        0.048780\n",
       "2        0.058824\n",
       "3        0.107143\n",
       "4        0.029412\n",
       "           ...   \n",
       "26427    0.032258\n",
       "26428    0.037037\n",
       "26429    0.078947\n",
       "26430    0.008403\n",
       "26431    0.038462\n",
       "Name: body, Length: 26432, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouns_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_train, pro_test, y_train, y_test = train_test_split(pronouns_vector, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Capital Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capitalization_Normalizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def capital_percentage(self, lst):\n",
    "        return sum([1 if x.isupper() else 0 for x in lst]) / len(lst)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        tokens = pd.Series(X).apply(nltk.word_tokenize)\n",
    "        return tokens.apply(self.capital_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals = Capitalization_Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capitalization_Normalizer()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitals.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals_vector = capitals.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_train, cap_test, y_train, y_test = train_test_split(capitals_vector, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Profanity Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "profanity_count = X.apply(check_profanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_train, prof_test, y_train, y_test = train_test_split(profanity_count, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Text Length Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = X.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train, len_test, y_train, y_test = train_test_split(text_length, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatize X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply above function to data\n",
    "\n",
    "processed_comments = list(map(process_comment, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with lemmatized output\n",
    "lemmatized_output = []\n",
    "\n",
    "for comment in processed_comments:\n",
    "    lemmed = ' '.join([lemmatizer.lemmatize(w) for w in comment])\n",
    "    lemmatized_output.append(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this to 'lemmatized_output' if you are including lemma (see above)\n",
    "X_lem = lemmatized_output\n",
    "\n",
    "y_lem = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Lexical Diversity Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_div = pd.Series(X_lem).apply(lexical_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_train, lex_test, y_train, y_test = train_test_split(lex_div, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "        self.dim = 300\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Doc.vector defaults to an average of the token vectors.\n",
    "        # https://spacy.io/api/doc#vector\n",
    "        \n",
    "        return [self.nlp(text).vector for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "embeddings_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "        (\"reduce_dim\", TruncatedSVD(50)),\n",
    "        (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "    ]\n",
    ")\n",
    "embeddings_pipeline.fit(X_train_lem, y_train_lem)\n",
    "y_pred = embeddings_pipeline.predict(X_test_lem)\n",
    "cr = classification_report(y_test_lem, y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_lem, y_pred)\n",
    "f1 = f1_score(y_test_lem, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.914181</td>\n",
       "      <td>0.908673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy        f1\n",
       "0     Dummy  0.500000  0.000000\n",
       "1  word2vec  0.914181  0.908673"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'word2vec', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"tfidf\", TfidfVectorizer()),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# tfidf_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = tfidf_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # individual pipelines minus the estimator step: \n",
    "# tfidf_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"tfidf\", TfidfVectorizer()),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# embeddings_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "#         (\"reduce_dim\", TruncatedSVD(50)),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_features = FeatureUnion(\n",
    "#     transformer_list=[\n",
    "#         (\"tfidf\", tfidf_pipeline),\n",
    "#         (\"embeddings\", embeddings_pipeline),\n",
    "#         #(try adding a pipeline that is just the dense columns)\n",
    "#     ]\n",
    "# )\n",
    "# final_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"combined_features\", combined_features),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = final_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining Sparse with Dense**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_input(pro_tr = None, pro_te = None, \n",
    "                     cap_tr = None, cap_te = None, \n",
    "                     prof_tr = None, prof_te = None, \n",
    "                     len_tr = None, len_te = None,\n",
    "                     lex_tr = None, lex_te = None,\n",
    "                     stop_tr = None, stop_te = None):\n",
    "    \n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "    tfidf_data_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "    tfidf_data_test_lem = tfidf.transform(X_test_lem)\n",
    "    \n",
    "    \n",
    "    tfidf_data_train_lem = pd.DataFrame(tfidf_data_train_lem.toarray(), columns=tfidf.vocabulary_.keys())\n",
    "\n",
    "    tfidf_data_test_lem = pd.DataFrame(tfidf_data_test_lem.toarray(), columns=tfidf.vocabulary_.keys())\n",
    "    \n",
    "    print(\"Finished Part 1\")\n",
    "\n",
    "     \n",
    "    if str(type(pro_tr)) != str(type(None)) and str(type(pro_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xpronouns'] = pro_tr\n",
    "        tfidf_data_test_lem['Xpronouns'] = pro_te\n",
    "        print('finished pronoun_test')\n",
    "        \n",
    "    if str(type(cap_tr)) != str(type(None)) and str(type(cap_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xcapitals'] = cap_tr\n",
    "        tfidf_data_test_lem['Xcapitals'] = cap_te\n",
    "        print('finished capital_test')\n",
    "\n",
    "        \n",
    "    if str(type(prof_tr)) != str(type(None)) and str(type(prof_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xprofanity'] = prof_tr\n",
    "        tfidf_data_test_lem['Xprofanity'] = prof_te\n",
    "        print('finished profanity_test')\n",
    "    \n",
    "    if str(type(len_tr)) != str(type(None)) and str(type(len_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xlength'] = len_tr\n",
    "        tfidf_data_test_lem['Xlength'] = len_te\n",
    "        print('finished length_test')\n",
    "    \n",
    "    if str(type(lex_tr)) != str(type(None)) and str(type(lex_tr)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xlexical'] = lex_tr\n",
    "        tfidf_data_test_lem['Xlexical'] = lex_te\n",
    "        print('finished lexical_test')\n",
    "    \n",
    "    if str(type(stop_tr)) != str(type(None)) and str(type(stop_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xstopwords'] = stop_tr\n",
    "        tfidf_data_test_lem['Xstopwords'] = stop_te\n",
    "\n",
    "        \n",
    "    train_columns = tfidf_data_train_lem.columns\n",
    "    \n",
    "    tfidf_data_train_lem = scipy.sparse.csr_matrix(tfidf_data_train_lem)\n",
    "    \n",
    "    print(\"Finished train sparsing\")\n",
    "    \n",
    "    tfidf_data_test_lem = scipy.sparse.csr_matrix(tfidf_data_test_lem)\n",
    "    \n",
    "    print(\"Finished test sparsing\")\n",
    "\n",
    "    \n",
    "    return tfidf_data_train_lem, tfidf_data_test_lem, train_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dif dataframes to test models with, 1 with each feature appended to Tf IDF and one with all 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_columns = classifier_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished pronoun_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished profanity_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished capital_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished length_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "pro_train2, pro_test2, pro_columns = classifier_input(pro_tr = pro_train, pro_te = pro_test)\n",
    "\n",
    "prof_train2, prof_test2, prof_columns = classifier_input(prof_tr = prof_train, prof_te = prof_test)\n",
    "\n",
    "cap_train2, cap_test2, cap_columns = classifier_input(cap_tr = cap_train, cap_te = cap_test)\n",
    "\n",
    "len_train2, len_test2, len_columns = classifier_input(len_tr = len_train, len_te = len_test)\n",
    "\n",
    "lex_train2, lex_test2, lex_columns = classifier_input(lex_tr = lex_train, lex_te = lex_test)\n",
    "\n",
    "stop_train2, stop_test2, stop_columns = classifier_input(stop_tr = stop_train, stop_te = stop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished pronoun_test\n",
      "finished capital_test\n",
      "finished profanity_test\n",
      "finished length_test\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "combined_train, combined_test, combined_columns = classifier_input(pro_tr = pro_train, pro_te = pro_test, \n",
    "                                                                   prof_tr = prof_train, prof_te = prof_test, \n",
    "                                                                   cap_tr = cap_train, cap_te = cap_test, \n",
    "                                                                   len_tr = len_train, len_te = len_test, \n",
    "                                                                   lex_tr = lex_train, lex_te = lex_test, \n",
    "                                                                   stop_tr = stop_train, stop_te = stop_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KMeans**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_2 = KMeans(n_clusters=2).fit(X_train)\n",
    "k_means_3 = KMeans(n_clusters=3).fit(X_train)\n",
    "k_means_4 = KMeans(n_clusters=4).fit(X_train)\n",
    "k_means_5 = KMeans(n_clusters=5).fit(X_train)\n",
    "k_means_6 = KMeans(n_clusters=6).fit(X_train)\n",
    "k_means_7 = KMeans(n_clusters=7).fit(X_train)\n",
    "\n",
    "k_list = [k_means_2, k_means_3, k_means_4, k_means_5, k_means_6, k_means_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_score = []\n",
    "\n",
    "for model in k_list:\n",
    "    labels = model.labels_\n",
    "    sil_score.append(silhouette_score(X_train.toarray(), labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot([2, 3, 4, 5, 6, 7], sil_score)\n",
    "plt.xticks([2,3,4,5,6,7])\n",
    "plt.title('Silhouette Scores for Different Values of K')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.xlabel('K=')\n",
    "plt.savefig(\"../Pics/sil_score.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(X_train)\n",
    "kmeans_preds = kmeans.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_lem, kmeans_preds)\n",
    "f1 = f1_score(y_test_lem, kmeans_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': 'kmeans_tfidf', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hierarchical**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hierarchical clustering takes too long to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_clust = AgglomerativeClustering(n_clusters=2)\n",
    "agg_clust.fit(X_train.toarray())\n",
    "agg_clust_preds = agg_clust.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No Added Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc_basic_tfidf = RandomForestClassifier(n_estimators=200,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_basic_tfidf.fit(X_train, y_train_lem)\n",
    "rf_test_preds = rfc_basic_tfidf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': 'rfc_basic_tfidf', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Stopwrods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_stop = RandomForestClassifier(n_estimators=350,max_features = 'log2', random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_stop.fit(stop_train2, y_train_lem)\n",
    "rf_test_preds = rfc_stop.predict(stop_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': 'rfc_STOP', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Pronouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rfc_pro = RandomForestClassifier(n_estimators=300,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_pro.fit(pro_train2, y_train_lem)\n",
    "rf_test_preds = rfc_pro.predict(pro_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': 'rfc_pro', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(pro_columns, rfc_pro.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_test_lem, rf_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Right', 'Left'], yticklabels=['Right', 'Left'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RCF Profanity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc_prof = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_prof.fit(prof_train2, y_train_lem)\n",
    "rf_test_preds = rfc_prof.predict(prof_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Profanity')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': 'rfc_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(prof_columns, rfc_prof.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's interesting that we have a lower accuracy with this model, yet our newly added feature ranks as higher importance than pronouns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Capital**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc_cap = RandomForestClassifier(n_estimators=200,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_cap.fit(cap_train2, y_train_lem)\n",
    "rf_test_preds = rfc_cap.predict(cap_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': 'rfc_cap', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(cap_columns, rfc_cap.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_len = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_len.fit(len_train2, y_train_lem)\n",
    "rf_test_preds = rfc_len.predict(len_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': 'rfc_len', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Lexical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_lex = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_lex.fit(lex_train2, y_train_lem)\n",
    "rf_test_preds = rfc_lex.predict(lex_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Lexical')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': 'rfc_lex', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Combined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc_combined = RandomForestClassifier(n_estimators=350,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_combined.fit(combined_train, y_train_lem)\n",
    "rf_test_preds = rfc_combined.predict(combined_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': 'rfc_combined', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(combined_columns, rfc_combined.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Combined (Lexical + Prof)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished profanity_test\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "lex_prof_train, lex_prof_test, lex_prof_columns = classifier_input(prof_tr = prof_train, prof_te = prof_test, \n",
    "                                                                   lex_tr = lex_train, lex_te = lex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9434\n",
      "\n",
      "F1 Score: 0.9406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_lex_prof = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_lex_prof.fit(lex_prof_train, y_train_lem)\n",
    "rf_test_preds = rfc_lex_prof.predict(lex_prof_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': 'rfc_lex_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rfc_lex_prof</td>\n",
       "      <td>0.943364</td>\n",
       "      <td>0.940617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.943147</td>\n",
       "      <td>0.940390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942931</td>\n",
       "      <td>0.940231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942823</td>\n",
       "      <td>0.940043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.941094</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy        f1\n",
       "1         rfc_STOP  0.944228  0.941457\n",
       "7     rfc_combined  0.944228  0.941390\n",
       "8     rfc_lex_prof  0.943364  0.940617\n",
       "6          rfc_lex  0.943147  0.940390\n",
       "5          rfc_len  0.942931  0.940231\n",
       "3         rfc_prof  0.942823  0.940043\n",
       "2          rfc_pro  0.942715  0.940032\n",
       "0  rfc_basic_tfidf  0.942283  0.939538\n",
       "4          rfc_cap  0.941094  0.938300"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.sort_values(by='accuracy',ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open('rfc_combined.pickle', 'wb') as f:\n",
    "    pickle.dump(rfc_combined, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished profanity_test\n",
      "finished length_test\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "top_train, top_test, top_columns = classifier_input(prof_tr = prof_train, prof_te = prof_test,\n",
    "                                                    len_tr = len_train, len_te = len_test,  \n",
    "                                                    stop_tr = stop_train, stop_te = stop_test,\n",
    "                                                    lex_tr = lex_train, lex_te = lex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9449\n",
      "\n",
      "F1 Score: 0.9422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_top = RandomForestClassifier(n_estimators=200,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_top.fit(top_train, y_train_lem)\n",
    "rf_test_preds = rfc_top.predict(top_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_lex_prof</td>\n",
       "      <td>0.943364</td>\n",
       "      <td>0.940617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.943147</td>\n",
       "      <td>0.940390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942931</td>\n",
       "      <td>0.940231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942823</td>\n",
       "      <td>0.940043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.941094</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rfc_top</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rfc_top</td>\n",
       "      <td>0.944877</td>\n",
       "      <td>0.942242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  accuracy        f1\n",
       "0          rfc_STOP  0.944228  0.941457\n",
       "1      rfc_combined  0.944228  0.941390\n",
       "2      rfc_lex_prof  0.943364  0.940617\n",
       "3           rfc_lex  0.943147  0.940390\n",
       "4           rfc_len  0.942931  0.940231\n",
       "5          rfc_prof  0.942823  0.940043\n",
       "6           rfc_pro  0.942715  0.940032\n",
       "7   rfc_basic_tfidf  0.942283  0.939538\n",
       "8           rfc_cap  0.941094  0.938300\n",
       "9           rfc_top  0.944228  0.941404\n",
       "10          rfc_top  0.944877  0.942242"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_top', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with Pronouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.9358\n",
      "\n",
      "F1 Score: 0.9342\n"
     ]
    }
   ],
   "source": [
    "svc_pro = SVC(verbose=1)\n",
    "svc_pro.fit(pro_train2, y_train_lem)\n",
    "rf_test_preds = svc_pro.predict(pro_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy        f1\n",
       "0            rfc_pro  0.934124  0.932712\n",
       "1           rfc_prof  0.933516  0.932238\n",
       "2            rfc_cap  0.936711  0.935484\n",
       "3            rfc_len  0.938993  0.937510\n",
       "4            rfc_len  0.940362  0.939112\n",
       "5       rfc_combined  0.936254  0.934847\n",
       "6  grid_rfc_combined  0.934581  0.933147\n",
       "7            svm_pro  0.935798  0.934165"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_pro', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with Profanity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Profanity\n",
      "Testing Accuracy: 0.9358\n",
      "\n",
      "F1 Score: 0.934\n"
     ]
    }
   ],
   "source": [
    "svc_prof = SVC(verbose=1)\n",
    "svc_prof.fit(prof_train2, y_train_lem)\n",
    "rf_test_preds = svc_prof.predict(prof_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Profanity')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy        f1\n",
       "0            rfc_pro  0.934124  0.932712\n",
       "1           rfc_prof  0.933516  0.932238\n",
       "2            rfc_cap  0.936711  0.935484\n",
       "3            rfc_len  0.938993  0.937510\n",
       "4            rfc_len  0.940362  0.939112\n",
       "5       rfc_combined  0.936254  0.934847\n",
       "6  grid_rfc_combined  0.934581  0.933147\n",
       "7            svm_pro  0.935798  0.934165\n",
       "8           svm_prof  0.935798  0.934021"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Capitals\n",
      "Testing Accuracy: 0.9356\n",
      "\n",
      "F1 Score: 0.9339\n"
     ]
    }
   ],
   "source": [
    "svc_cap = SVC(verbose=1)\n",
    "svc_cap.fit(cap_train2, y_train_lem)\n",
    "rf_test_preds = svc_cap.predict(cap_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Capitals')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.936693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm_cap</td>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.933937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0       rfc_pro  0.934124  0.932712\n",
       "1      rfc_prof  0.933516  0.932238\n",
       "2       rfc_cap  0.936711  0.935484\n",
       "3  rfc_combined  0.938080  0.936693\n",
       "4       svm_pro  0.935798  0.934165\n",
       "5      svm_prof  0.935798  0.934021\n",
       "6       svm_cap  0.935646  0.933937"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_cap', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Capitals\n",
      "Testing Accuracy: 0.9355\n",
      "\n",
      "F1 Score: 0.9338\n"
     ]
    }
   ],
   "source": [
    "svc_combined = SVC(verbose=1)\n",
    "svc_combined.fit(combined_train, y_train_lem)\n",
    "rf_test_preds = svc_combined.predict(combined_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Capitals')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.936693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm_cap</td>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.933937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_combined</td>\n",
       "      <td>0.935494</td>\n",
       "      <td>0.933833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0       rfc_pro  0.934124  0.932712\n",
       "1      rfc_prof  0.933516  0.932238\n",
       "2       rfc_cap  0.936711  0.935484\n",
       "3  rfc_combined  0.938080  0.936693\n",
       "4       svm_pro  0.935798  0.934165\n",
       "5      svm_prof  0.935798  0.934021\n",
       "6       svm_cap  0.935646  0.933937\n",
       "7  svm_combined  0.935494  0.933833"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_combined', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MN Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "tfidf_data_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "tfidf_data_test_lem = tfidf.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes model accuracy\n",
      "Testing Accuracy: 0.9229\n",
      "\n",
      "F1 Score: 0.9233\n"
     ]
    }
   ],
   "source": [
    "mnb_lemma = MultinomialNB()\n",
    "mnb_lemma.fit(tfidf_data_train_lem, y_train_lem)\n",
    "mnb_test_preds = mnb_lemma.predict(tfidf_data_test_lem)\n",
    "\n",
    "mnb_acc_score_lem = accuracy_score(y_test_lem, mnb_test_preds)\n",
    "mnb_f1_score_lem = f1_score(y_test_lem, mnb_test_preds)\n",
    "print('Multinomial Naive Bayes model accuracy')\n",
    "print(\"Testing Accuracy: {:.4}\".format(mnb_acc_score_lem))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(mnb_f1_score_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(y_test_lem, mnb_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Right', 'Left'], yticklabels=['Right', 'Left'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([13945,  6183,  7323,  8678,  9725,   142,  8214, 10630, 13450,\n",
       "             5728,\n",
       "            ...\n",
       "            17422,  5401,  8138, 14548, 12747, 16922, 17135,  1454,  1501,\n",
       "             9295],\n",
       "           dtype='int64', length=6573)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_lem.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-378-e4180468063b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test_lem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_test_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'right'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1652\u001b[0m             \u001b[0;31m# just raising\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1655\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                     \u001b[0;34m\"is no longer supported, see \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
     ]
    }
   ],
   "source": [
    "test = comments_df.loc[y_test_lem.index]\n",
    "test['pred'] = rf_test_preds\n",
    "test['pred'] = test['pred'].apply(lambda x: 'right' if x == 1 else 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-379-c79d526ba28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mguessed_right_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment_class\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mguessed_right_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mguessed_left_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment_class\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mguessed_left_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "guessed_right_wrong = test[(test.comment_class != test.pred) & (test.pred == 'right')]\n",
    "guessed_right_wrong.reset_index(drop=True, inplace=True)\n",
    "\n",
    "guessed_left_wrong = test[(test.comment_class != test.pred) & (test.pred == 'left')]\n",
    "guessed_left_wrong.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUESSED RIGHT BUT WE WERE WRONG\n",
      "_______________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'guessed_right_wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-380-d7cd6e846f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_______________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguessed_right_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guessed_right_wrong' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"GUESSED RIGHT BUT WE WERE WRONG\")\n",
    "print(\"_______________________________\")\n",
    "for i in range(0,50):\n",
    "    print(guessed_right_wrong.iloc[i].body)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUESSED LEFT BUT WE WERE WRONG\n",
      "______________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'guessed_left_wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-381-4c1d1ba7a9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"______________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguessed_left_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guessed_left_wrong' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"GUESSED LEFT BUT WE WERE WRONG\")\n",
    "print(\"______________________________\")\n",
    "for i in range(0,50):\n",
    "    print(guessed_left_wrong.iloc[i].body)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
