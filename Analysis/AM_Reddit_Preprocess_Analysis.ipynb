{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note, only using comments_df for now until we figure out if it is worth it to use the posts_df as well somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Import Packages, define functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import mysql.connector\n",
    "# some_file.py\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/brianmccabe/DataScience/Flatiron/mod4/Reddit_NLP/Scripts')\n",
    "#import config\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "import scipy\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stopwords(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    \n",
    "    return (len(tokens) - len(stopwords_removed)) / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can define a function that removes stopwords \n",
    "def process_comment(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_percentage(comment):\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    cap_count = 0\n",
    "    for item in tokens:\n",
    "        if item.isupper():\n",
    "            cap_count += 1\n",
    "    return cap_count/len(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_profanity(comment):\n",
    "    try:\n",
    "        profane = pd.read_csv(\"/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/profane_words.csv\", header=None)\n",
    "    except:\n",
    "        profane = pd.read_csv(\"profane_words.csv\", header=None)\n",
    "\n",
    "    profane = list(profane.loc[:,0])\n",
    "    count = 0\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    for word in tokens:\n",
    "        if word in profane:\n",
    "            count += 1\n",
    "    return count/len(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    \n",
    "    unique_words = len(set(tokens))\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "    return unique_words / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stopwords and punctuations\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords += list(string.punctuation)\n",
    "stopwords += [\"n't\", \"' '\", \"'re'\",\"”\",\"``\",\"“\",\"''\",\"’\",\"'s\",\"'re\",\"http\",\"https\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posts_df = pd.read_csv('/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/posts_df.csv', index_col=0)\n",
    "try:\n",
    "    comments_df = pd.read_csv('/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/comments_df.csv', index_col=0)\n",
    "except:\n",
    "    comments_df = pd.read_csv(\"comments_df.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203837"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posts_df.columns = ['id_num', 'post_title', 'post_author', 'post_upvote_ratio', 'post_id', 'post_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.columns = ['id_num', 'body', 'comment_id', 'parent_id', 'post_id', 'author', 'score', 'comment_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = '\\w+_(\\w+)'\n",
    "p = re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.post_id = comments_df.post_id.apply(lambda x: p.findall(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RID OF NEGATIVE SCORES (a negative score in a conservative subreddit could be a brigader for example)\n",
    "comments_df = comments_df[comments_df.score > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = comments_df[['body', 'comment_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "right    22712\n",
       "left     22397\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "leaning_map = {'right': 1, 'left': 0}\n",
    "df.comment_class = df.comment_class.map(leaning_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-67af6b43cc2d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_len'] = df['body'].map(lambda x: len(x))\n"
     ]
    }
   ],
   "source": [
    "df['text_len'] = df['body'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.text_len >= 100]\n",
    "df.drop('text_len', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13216\n",
       "1    12177\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13216\n",
       "0    13216\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "right = df[df.comment_class == 1]\n",
    "left = df[df.comment_class == 0]\n",
    "\n",
    "right_upsampled = resample(right,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(left), # match number in majority class\n",
    "                          random_state=42) \n",
    "df = pd.concat([left, right_upsampled])\n",
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['body']\n",
    "y = df['comment_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        As a Lesbian, I get a lot of backlash when peo...\n",
       "1        “*These are radical islamic terrorists and she...\n",
       "2        I hope Gov. Whitmer still has all that extra s...\n",
       "3        She's not wrong. I hope this woman goes places...\n",
       "4        The Orange Tweeter's irresponsible actions hav...\n",
       "                               ...                        \n",
       "26427    Imagine thinking *this* is the most pressing i...\n",
       "26428    This post is misleading and should either be c...\n",
       "26429    Claiming she’ll use an executive order if cong...\n",
       "26430    Here is a better timeline of events that lead ...\n",
       "26431    Whats bullshit is that this is the first I hav...\n",
       "Name: body, Length: 26432, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count Stopwords Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_count = X.apply(count_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_train, stop_test, y_train, y_test = train_test_split(stopwords_count, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Pronoun Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from Pronouns import Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Pronouns(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "    \n",
    "#     def count_pronouns(self, comment):\n",
    "#         comment = comment.lower()\n",
    "#         tokens = nltk.word_tokenize(comment)\n",
    "\n",
    "#         pos_tags = [i[1] for i in nltk.pos_tag(tokens)]\n",
    "#         count = 0\n",
    "#         pronouns = ['PRP','PRP$','WP','WP$']\n",
    "#         for pos in pos_tags:\n",
    "#             if pos in pronouns:\n",
    "#                 count += 1\n",
    "\n",
    "#         return count / len(tokens)\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         return pd.Series(X).apply(self.count_pronouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = Pronouns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pronouns()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouns.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns_vector = pronouns.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.106195\n",
       "1        0.048780\n",
       "2        0.058824\n",
       "3        0.107143\n",
       "4        0.029412\n",
       "           ...   \n",
       "26427    0.032258\n",
       "26428    0.037037\n",
       "26429    0.078947\n",
       "26430    0.008403\n",
       "26431    0.038462\n",
       "Name: body, Length: 26432, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouns_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_train, pro_test, y_train, y_test = train_test_split(pronouns_vector, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Capital Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capitalization_Normalizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def capital_percentage(self, lst):\n",
    "        return sum([1 if x.isupper() else 0 for x in lst]) / len(lst)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        tokens = pd.Series(X).apply(nltk.word_tokenize)\n",
    "        return tokens.apply(self.capital_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals = Capitalization_Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capitalization_Normalizer()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitals.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals_vector = capitals.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_train, cap_test, y_train, y_test = train_test_split(capitals_vector, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Profanity Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "profanity_count = X.apply(check_profanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_train, prof_test, y_train, y_test = train_test_split(profanity_count, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Text Length Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = X.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train, len_test, y_train, y_test = train_test_split(text_length, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatize X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply above function to data\n",
    "\n",
    "processed_comments = list(map(process_comment, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with lemmatized output\n",
    "lemmatized_output = []\n",
    "\n",
    "for comment in processed_comments:\n",
    "    lemmed = ' '.join([lemmatizer.lemmatize(w) for w in comment])\n",
    "    lemmatized_output.append(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this to 'lemmatized_output' if you are including lemma (see above)\n",
    "X_lem = lemmatized_output\n",
    "\n",
    "y_lem = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Lexical Diversity Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_div = pd.Series(X_lem).apply(lexical_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_train, lex_test, y_train, y_test = train_test_split(lex_div, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "        self.dim = 300\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Doc.vector defaults to an average of the token vectors.\n",
    "        # https://spacy.io/api/doc#vector\n",
    "        \n",
    "        return [self.nlp(text).vector for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "embeddings_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "        (\"reduce_dim\", TruncatedSVD(50)),\n",
    "        (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "    ]\n",
    ")\n",
    "embeddings_pipeline.fit(X_train_lem, y_train_lem)\n",
    "y_pred = embeddings_pipeline.predict(X_test_lem)\n",
    "cr = classification_report(y_test_lem, y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.881859</td>\n",
       "      <td>0.968268</td>\n",
       "      <td>0.923045</td>\n",
       "      <td>4664.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.964173</td>\n",
       "      <td>0.868134</td>\n",
       "      <td>0.913637</td>\n",
       "      <td>4588.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.918612</td>\n",
       "      <td>0.918612</td>\n",
       "      <td>0.918612</td>\n",
       "      <td>0.918612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.923016</td>\n",
       "      <td>0.918201</td>\n",
       "      <td>0.918341</td>\n",
       "      <td>9252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.922678</td>\n",
       "      <td>0.918612</td>\n",
       "      <td>0.918380</td>\n",
       "      <td>9252.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.881859  0.968268  0.923045  4664.000000\n",
       "1              0.964173  0.868134  0.913637  4588.000000\n",
       "accuracy       0.918612  0.918612  0.918612     0.918612\n",
       "macro avg      0.923016  0.918201  0.918341  9252.000000\n",
       "weighted avg   0.922678  0.918612  0.918380  9252.000000"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"tfidf\", TfidfVectorizer()),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# tfidf_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = tfidf_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # individual pipelines minus the estimator step: \n",
    "# tfidf_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"tfidf\", TfidfVectorizer()),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# embeddings_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "#         (\"reduce_dim\", TruncatedSVD(50)),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_features = FeatureUnion(\n",
    "#     transformer_list=[\n",
    "#         (\"tfidf\", tfidf_pipeline),\n",
    "#         (\"embeddings\", embeddings_pipeline),\n",
    "#         #(try adding a pipeline that is just the dense columns)\n",
    "#     ]\n",
    "# )\n",
    "# final_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"combined_features\", combined_features),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = final_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining Sparse with Dense**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_input(pro_tr = None, pro_te = None, \n",
    "                     cap_tr = None, cap_te = None, \n",
    "                     prof_tr = None, prof_te = None, \n",
    "                     len_tr = None, len_te = None,\n",
    "                     lex_tr = None, lex_te = None,\n",
    "                     stop_tr = None, stop_te = None):\n",
    "    \n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "    tfidf_data_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "    tfidf_data_test_lem = tfidf.transform(X_test_lem)\n",
    "    \n",
    "    \n",
    "    tfidf_data_train_lem = pd.DataFrame(tfidf_data_train_lem.toarray(), columns=tfidf.vocabulary_.keys())\n",
    "\n",
    "    tfidf_data_test_lem = pd.DataFrame(tfidf_data_test_lem.toarray(), columns=tfidf.vocabulary_.keys())\n",
    "    \n",
    "    print(\"Finished Part 1\")\n",
    "\n",
    "     \n",
    "    if str(type(pro_tr)) != str(type(None)) and str(type(pro_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xpronouns'] = pro_tr\n",
    "        tfidf_data_test_lem['Xpronouns'] = pro_te\n",
    "        print('finished pronoun_test')\n",
    "        \n",
    "    if str(type(cap_tr)) != str(type(None)) and str(type(cap_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xcapitals'] = cap_tr\n",
    "        tfidf_data_test_lem['Xcapitals'] = cap_te\n",
    "        print('finished capital_test')\n",
    "\n",
    "        \n",
    "    if str(type(prof_tr)) != str(type(None)) and str(type(prof_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xprofanity'] = prof_tr\n",
    "        tfidf_data_test_lem['Xprofanity'] = prof_te\n",
    "        print('finished profanity_test')\n",
    "    \n",
    "    if str(type(len_tr)) != str(type(None)) and str(type(len_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xlength'] = len_tr\n",
    "        tfidf_data_test_lem['Xlength'] = len_te\n",
    "        print('finished length_test')\n",
    "    \n",
    "    if str(type(lex_tr)) != str(type(None)) and str(type(lex_tr)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xlexical'] = lex_tr\n",
    "        tfidf_data_test_lem['Xlexical'] = lex_te\n",
    "        print('finished lexical_test')\n",
    "    \n",
    "    if str(type(stop_tr)) != str(type(None)) and str(type(stop_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xstopwords'] = stop_tr\n",
    "        tfidf_data_test_lem['Xstopwords'] = stop_te\n",
    "\n",
    "        \n",
    "    train_columns = tfidf_data_train_lem.columns\n",
    "    \n",
    "    tfidf_data_train_lem = scipy.sparse.csr_matrix(tfidf_data_train_lem)\n",
    "    \n",
    "    print(\"Finished train sparsing\")\n",
    "    \n",
    "    tfidf_data_test_lem = scipy.sparse.csr_matrix(tfidf_data_test_lem)\n",
    "    \n",
    "    print(\"Finished test sparsing\")\n",
    "\n",
    "    \n",
    "    return tfidf_data_train_lem, tfidf_data_test_lem, train_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dif dataframes to test models with, 1 with each feature appended to Tf IDF and one with all 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_columns = classifier_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-19ba6c88c51f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpro_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpro_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpro_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpro_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpro_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpro_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpro_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprof_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprof_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprof_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprof_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprof_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprof_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcap_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier_input' is not defined"
     ]
    }
   ],
   "source": [
    "pro_train2, pro_test2, pro_columns = classifier_input(pro_tr = pro_train, pro_te = pro_test)\n",
    "\n",
    "prof_train2, prof_test2, prof_columns = classifier_input(prof_tr = prof_train, prof_te = prof_test)\n",
    "\n",
    "cap_train2, cap_test2, cap_columns = classifier_input(cap_tr = cap_train, cap_te = cap_test)\n",
    "\n",
    "len_train2, len_test2, len_columns = classifier_input(len_tr = len_train, len_te = len_test)\n",
    "\n",
    "lex_train2, lex_test2, lex_columns = classifier_input(lex_tr = lex_train, lex_te = lex_test)\n",
    "\n",
    "stop_train2, stop_test2, stop_columns = classifier_input(stop_tr = stop_train, stop_te = stop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train, combined_test, combined_columns = classifier_input(pro_tr = pro_train, pro_te = pro_test, \n",
    "                                                                   prof_tr = prof_train, prof_te = prof_test, \n",
    "                                                                   cap_tr = cap_train, cap_te = cap_test, \n",
    "                                                                   len_tr = len_train, len_te = len_test, \n",
    "                                                                   lex_tr = lex_train, lex_te = lex_test, \n",
    "                                                                   stop_tr = stop_train, stop_te = stop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, accuracy, f1]\n",
       "Index: []"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns = ['model','accuracy','f1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No Added Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_basic_tfidf = RandomForestClassifier(n_estimators=200,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_basic_tfidf.fit(X_train, y_train_lem)\n",
    "rf_test_preds = rfc_basic_tfidf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.9423\n",
      "\n",
      "F1 Score: 0.9395\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy        f1\n",
       "0  rfc_basic_tfidf  0.942283  0.939538"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_basic_tfidf', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Stopwrods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 350 out of 350 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.9442\n",
      "\n",
      "F1 Score: 0.9415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 350 out of 350 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_stop = RandomForestClassifier(n_estimators=350,max_features = 'log2', random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_stop.fit(stop_train2, y_train_lem)\n",
    "rf_test_preds = rfc_stop.predict(stop_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy        f1\n",
       "0  rfc_basic_tfidf  0.942283  0.939538\n",
       "1         rfc_STOP  0.944228  0.941457"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_STOP', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Pronouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.9427\n",
      "\n",
      "F1 Score: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_pro = RandomForestClassifier(n_estimators=300,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_pro.fit(pro_train2, y_train_lem)\n",
    "rf_test_preds = rfc_pro.predict(pro_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.940032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy        f1\n",
       "0  rfc_basic_tfidf  0.942283  0.939538\n",
       "1         rfc_STOP  0.944228  0.941457\n",
       "2          rfc_pro  0.942715  0.940032"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_pro', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(pro_columns, rfc_pro.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catalyst</td>\n",
       "      <td>0.019577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fizzled</td>\n",
       "      <td>0.014520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xpronouns</td>\n",
       "      <td>0.008502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ghostwriting</td>\n",
       "      <td>0.003827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>railroad</td>\n",
       "      <td>0.003419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>depot</td>\n",
       "      <td>0.003409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.003091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kidnapper</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>journals</td>\n",
       "      <td>0.002889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>appointing</td>\n",
       "      <td>0.002878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance\n",
       "0      catalyst    0.019577\n",
       "1       fizzled    0.014520\n",
       "2     Xpronouns    0.008502\n",
       "3  ghostwriting    0.003827\n",
       "4      railroad    0.003419\n",
       "5         depot    0.003409\n",
       "6          1990    0.003091\n",
       "7     kidnapper    0.003001\n",
       "8      journals    0.002889\n",
       "9    appointing    0.002878"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_test_lem, rf_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Right', 'Left'], yticklabels=['Right', 'Left'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RCF Profanity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    5.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Profanity\n",
      "Testing Accuracy: 0.9428\n",
      "\n",
      "F1 Score: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_prof = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_prof.fit(prof_train2, y_train_lem)\n",
    "rf_test_preds = rfc_prof.predict(prof_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Profanity')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942823</td>\n",
       "      <td>0.940043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy        f1\n",
       "0  rfc_basic_tfidf  0.942283  0.939538\n",
       "1         rfc_STOP  0.944228  0.941457\n",
       "2          rfc_pro  0.942715  0.940032\n",
       "3         rfc_prof  0.942823  0.940043"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(prof_columns, rfc_prof.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catalyst</td>\n",
       "      <td>0.020277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fizzled</td>\n",
       "      <td>0.014301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xprofanity</td>\n",
       "      <td>0.009050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ghostwriting</td>\n",
       "      <td>0.003734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depot</td>\n",
       "      <td>0.003551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>railroad</td>\n",
       "      <td>0.003353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kidnapper</td>\n",
       "      <td>0.003037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.002922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fuckjob</td>\n",
       "      <td>0.002834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>journals</td>\n",
       "      <td>0.002833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance\n",
       "0      catalyst    0.020277\n",
       "1       fizzled    0.014301\n",
       "2    Xprofanity    0.009050\n",
       "3  ghostwriting    0.003734\n",
       "4         depot    0.003551\n",
       "5      railroad    0.003353\n",
       "6     kidnapper    0.003037\n",
       "7          1990    0.002922\n",
       "8       fuckjob    0.002834\n",
       "9      journals    0.002833"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's interesting that we have a lower accuracy with this model, yet our newly added feature ranks as higher importance than pronouns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Capital**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9411\n",
      "\n",
      "F1 Score: 0.9383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_cap = RandomForestClassifier(n_estimators=200,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_cap.fit(cap_train2, y_train_lem)\n",
    "rf_test_preds = rfc_cap.predict(cap_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942823</td>\n",
       "      <td>0.940043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.941094</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy        f1\n",
       "0  rfc_basic_tfidf  0.942283  0.939538\n",
       "1         rfc_STOP  0.944228  0.941457\n",
       "2          rfc_pro  0.942715  0.940032\n",
       "3         rfc_prof  0.942823  0.940043\n",
       "4          rfc_cap  0.941094  0.938300"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_cap', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(cap_columns, rfc_cap.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catalyst</td>\n",
       "      <td>0.020479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fizzled</td>\n",
       "      <td>0.013760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xcapitals</td>\n",
       "      <td>0.007053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ghostwriting</td>\n",
       "      <td>0.003660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depot</td>\n",
       "      <td>0.003487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>railroad</td>\n",
       "      <td>0.003277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kidnapper</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>journals</td>\n",
       "      <td>0.003033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>appointing</td>\n",
       "      <td>0.002871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance\n",
       "0      catalyst    0.020479\n",
       "1       fizzled    0.013760\n",
       "2     Xcapitals    0.007053\n",
       "3  ghostwriting    0.003660\n",
       "4         depot    0.003487\n",
       "5      railroad    0.003277\n",
       "6     kidnapper    0.003100\n",
       "7      journals    0.003033\n",
       "8          1990    0.003011\n",
       "9    appointing    0.002871"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9429\n",
      "\n",
      "F1 Score: 0.9402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_len = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_len.fit(len_train2, y_train_lem)\n",
    "rf_test_preds = rfc_len.predict(len_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942823</td>\n",
       "      <td>0.940043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.941094</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942931</td>\n",
       "      <td>0.940231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy        f1\n",
       "0  rfc_basic_tfidf  0.942283  0.939538\n",
       "1         rfc_STOP  0.944228  0.941457\n",
       "2          rfc_pro  0.942715  0.940032\n",
       "3         rfc_prof  0.942823  0.940043\n",
       "4          rfc_cap  0.941094  0.938300\n",
       "5          rfc_len  0.942931  0.940231"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_len', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Lexical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Lexical\n",
      "Testing Accuracy: 0.9431\n",
      "\n",
      "F1 Score: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_lex = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_lex.fit(lex_train2, y_train_lem)\n",
    "rf_test_preds = rfc_lex.predict(lex_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Lexical')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942823</td>\n",
       "      <td>0.940043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.941094</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942931</td>\n",
       "      <td>0.940231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.943147</td>\n",
       "      <td>0.940390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy        f1\n",
       "0  rfc_basic_tfidf  0.942283  0.939538\n",
       "1         rfc_STOP  0.944228  0.941457\n",
       "2          rfc_pro  0.942715  0.940032\n",
       "3         rfc_prof  0.942823  0.940043\n",
       "4          rfc_cap  0.941094  0.938300\n",
       "5          rfc_len  0.942931  0.940231\n",
       "6          rfc_lex  0.943147  0.940390"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_lex', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Combined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 350 out of 350 | elapsed:    7.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9442\n",
      "\n",
      "F1 Score: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 350 out of 350 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_combined = RandomForestClassifier(n_estimators=350,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_combined.fit(combined_train, y_train_lem)\n",
    "rf_test_preds = rfc_combined.predict(combined_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942823</td>\n",
       "      <td>0.940043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.941094</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942931</td>\n",
       "      <td>0.940231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.943147</td>\n",
       "      <td>0.940390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy        f1\n",
       "0  rfc_basic_tfidf  0.942283  0.939538\n",
       "1         rfc_STOP  0.944228  0.941457\n",
       "2          rfc_pro  0.942715  0.940032\n",
       "3         rfc_prof  0.942823  0.940043\n",
       "4          rfc_cap  0.941094  0.938300\n",
       "5          rfc_len  0.942931  0.940231\n",
       "6          rfc_lex  0.943147  0.940390\n",
       "7     rfc_combined  0.944228  0.941390"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_combined', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(combined_columns, rfc_combined.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catalyst</td>\n",
       "      <td>0.019090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fizzled</td>\n",
       "      <td>0.015221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xprofanity</td>\n",
       "      <td>0.008969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xstopwords</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xlength</td>\n",
       "      <td>0.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xpronouns</td>\n",
       "      <td>0.007788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Xcapitals</td>\n",
       "      <td>0.006084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Xlexical</td>\n",
       "      <td>0.005592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ghostwriting</td>\n",
       "      <td>0.003979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>depot</td>\n",
       "      <td>0.003284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>journals</td>\n",
       "      <td>0.003248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fuckjob</td>\n",
       "      <td>0.002942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>face</td>\n",
       "      <td>0.002896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kidnapper</td>\n",
       "      <td>0.002835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>appointing</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>railroad</td>\n",
       "      <td>0.002560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>unbelievably</td>\n",
       "      <td>0.002521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.002496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>compass</td>\n",
       "      <td>0.002302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>will</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance\n",
       "0       catalyst    0.019090\n",
       "1        fizzled    0.015221\n",
       "2     Xprofanity    0.008969\n",
       "3     Xstopwords    0.008097\n",
       "4        Xlength    0.007800\n",
       "5      Xpronouns    0.007788\n",
       "6      Xcapitals    0.006084\n",
       "7       Xlexical    0.005592\n",
       "8   ghostwriting    0.003979\n",
       "9          depot    0.003284\n",
       "10      journals    0.003248\n",
       "11       fuckjob    0.002942\n",
       "12          face    0.002896\n",
       "13     kidnapper    0.002835\n",
       "14    appointing    0.002653\n",
       "15      railroad    0.002560\n",
       "16  unbelievably    0.002521\n",
       "17          1990    0.002496\n",
       "18       compass    0.002302\n",
       "19          will    0.002286"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gridsearch RFC Combined**\n",
    "- currently this has been replaced with combined(lexical + profanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 55, 60, 65, 70, 75, 80, 85, 90, 95]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(50,100,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = list(range(50,250,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 33.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 39.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 60, 70, 80, 90, 100, 110, 120,\n",
       "                                          130, 140, 150, 160, 170, 180, 190,\n",
       "                                          200, 210, 220, 230, 240]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'criterion': ['gini','entropy'],\n",
    "              'max_features': ['auto','sqrt','log2']\n",
    "        }\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, refit = True, verbose = 3, n_jobs = -1, scoring='accuracy')\n",
    "\n",
    "grid.fit(lex_prof_train, y_train_lem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_test_preds = grid.predict(lex_prof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'log2',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 240,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_lem, grid_test_preds)\n",
    "f1 = f1_score(y_test_lem, grid_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid RFC with Lemmatization Features and Combined\n",
      "Testing Accuracy: 0.9402\n",
      "\n",
      "F1 Score: 0.9383\n"
     ]
    }
   ],
   "source": [
    "print('Grid RFC with Lemmatization Features and Combined')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rfc_lex_prof</td>\n",
       "      <td>0.941427</td>\n",
       "      <td>0.939437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>grid_rfc_comb_lex_prof</td>\n",
       "      <td>0.940210</td>\n",
       "      <td>0.938295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  accuracy        f1\n",
       "0                  rfc_pro  0.934124  0.932712\n",
       "1                 rfc_prof  0.933516  0.932238\n",
       "2                  rfc_cap  0.936711  0.935484\n",
       "3                  rfc_len  0.938993  0.937510\n",
       "4                  rfc_len  0.940362  0.939112\n",
       "5             rfc_combined  0.936254  0.934847\n",
       "6        grid_rfc_combined  0.934581  0.933147\n",
       "7                  svm_pro  0.935798  0.934165\n",
       "8                 svm_prof  0.935798  0.934021\n",
       "9                  rfc_lex  0.940362  0.939112\n",
       "10            rfc_lex_prof  0.941427  0.939437\n",
       "11  grid_rfc_comb_lex_prof  0.940210  0.938295"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'grid_rfc_comb_lex_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Combined (Lexical + Prof)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished profanity_test\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "lex_prof_train, lex_prof_test, lex_prof_columns = classifier_input(prof_tr = prof_train, prof_te = prof_test, \n",
    "                                                                   lex_tr = lex_train, lex_te = lex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9434\n",
      "\n",
      "F1 Score: 0.9406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_lex_prof = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_lex_prof.fit(lex_prof_train, y_train_lem)\n",
    "rf_test_preds = rfc_lex_prof.predict(lex_prof_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': 'rfc_lex_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rfc_lex_prof</td>\n",
       "      <td>0.943364</td>\n",
       "      <td>0.940617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.943147</td>\n",
       "      <td>0.940390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942931</td>\n",
       "      <td>0.940231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942823</td>\n",
       "      <td>0.940043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.941094</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy        f1\n",
       "1         rfc_STOP  0.944228  0.941457\n",
       "7     rfc_combined  0.944228  0.941390\n",
       "8     rfc_lex_prof  0.943364  0.940617\n",
       "6          rfc_lex  0.943147  0.940390\n",
       "5          rfc_len  0.942931  0.940231\n",
       "3         rfc_prof  0.942823  0.940043\n",
       "2          rfc_pro  0.942715  0.940032\n",
       "0  rfc_basic_tfidf  0.942283  0.939538\n",
       "4          rfc_cap  0.941094  0.938300"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.sort_values(by='accuracy',ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open('rfc_combined.pickle', 'wb') as f:\n",
    "    pickle.dump(rfc_combined, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished profanity_test\n",
      "finished length_test\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "top_train, top_test, top_columns = classifier_input(prof_tr = prof_train, prof_te = prof_test,\n",
    "                                                    len_tr = len_train, len_te = len_test,  \n",
    "                                                    stop_tr = stop_train, stop_te = stop_test,\n",
    "                                                    lex_tr = lex_train, lex_te = lex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9449\n",
      "\n",
      "F1 Score: 0.9422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_top = RandomForestClassifier(n_estimators=200,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_top.fit(top_train, y_train_lem)\n",
    "rf_test_preds = rfc_top.predict(top_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_lex_prof</td>\n",
       "      <td>0.943364</td>\n",
       "      <td>0.940617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.943147</td>\n",
       "      <td>0.940390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942931</td>\n",
       "      <td>0.940231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942823</td>\n",
       "      <td>0.940043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.939538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.941094</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rfc_top</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.941404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rfc_top</td>\n",
       "      <td>0.944877</td>\n",
       "      <td>0.942242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  accuracy        f1\n",
       "0          rfc_STOP  0.944228  0.941457\n",
       "1      rfc_combined  0.944228  0.941390\n",
       "2      rfc_lex_prof  0.943364  0.940617\n",
       "3           rfc_lex  0.943147  0.940390\n",
       "4           rfc_len  0.942931  0.940231\n",
       "5          rfc_prof  0.942823  0.940043\n",
       "6           rfc_pro  0.942715  0.940032\n",
       "7   rfc_basic_tfidf  0.942283  0.939538\n",
       "8           rfc_cap  0.941094  0.938300\n",
       "9           rfc_top  0.944228  0.941404\n",
       "10          rfc_top  0.944877  0.942242"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_top', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with Pronouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.9358\n",
      "\n",
      "F1 Score: 0.9342\n"
     ]
    }
   ],
   "source": [
    "svc_pro = SVC(verbose=1)\n",
    "svc_pro.fit(pro_train2, y_train_lem)\n",
    "rf_test_preds = svc_pro.predict(pro_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy        f1\n",
       "0            rfc_pro  0.934124  0.932712\n",
       "1           rfc_prof  0.933516  0.932238\n",
       "2            rfc_cap  0.936711  0.935484\n",
       "3            rfc_len  0.938993  0.937510\n",
       "4            rfc_len  0.940362  0.939112\n",
       "5       rfc_combined  0.936254  0.934847\n",
       "6  grid_rfc_combined  0.934581  0.933147\n",
       "7            svm_pro  0.935798  0.934165"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_pro', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with Profanity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Profanity\n",
      "Testing Accuracy: 0.9358\n",
      "\n",
      "F1 Score: 0.934\n"
     ]
    }
   ],
   "source": [
    "svc_prof = SVC(verbose=1)\n",
    "svc_prof.fit(prof_train2, y_train_lem)\n",
    "rf_test_preds = svc_prof.predict(prof_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Profanity')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy        f1\n",
       "0            rfc_pro  0.934124  0.932712\n",
       "1           rfc_prof  0.933516  0.932238\n",
       "2            rfc_cap  0.936711  0.935484\n",
       "3            rfc_len  0.938993  0.937510\n",
       "4            rfc_len  0.940362  0.939112\n",
       "5       rfc_combined  0.936254  0.934847\n",
       "6  grid_rfc_combined  0.934581  0.933147\n",
       "7            svm_pro  0.935798  0.934165\n",
       "8           svm_prof  0.935798  0.934021"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Capitals\n",
      "Testing Accuracy: 0.9356\n",
      "\n",
      "F1 Score: 0.9339\n"
     ]
    }
   ],
   "source": [
    "svc_cap = SVC(verbose=1)\n",
    "svc_cap.fit(cap_train2, y_train_lem)\n",
    "rf_test_preds = svc_cap.predict(cap_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Capitals')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.936693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm_cap</td>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.933937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0       rfc_pro  0.934124  0.932712\n",
       "1      rfc_prof  0.933516  0.932238\n",
       "2       rfc_cap  0.936711  0.935484\n",
       "3  rfc_combined  0.938080  0.936693\n",
       "4       svm_pro  0.935798  0.934165\n",
       "5      svm_prof  0.935798  0.934021\n",
       "6       svm_cap  0.935646  0.933937"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_cap', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Capitals\n",
      "Testing Accuracy: 0.9355\n",
      "\n",
      "F1 Score: 0.9338\n"
     ]
    }
   ],
   "source": [
    "svc_combined = SVC(verbose=1)\n",
    "svc_combined.fit(combined_train, y_train_lem)\n",
    "rf_test_preds = svc_combined.predict(combined_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Capitals')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.936693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm_cap</td>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.933937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_combined</td>\n",
       "      <td>0.935494</td>\n",
       "      <td>0.933833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0       rfc_pro  0.934124  0.932712\n",
       "1      rfc_prof  0.933516  0.932238\n",
       "2       rfc_cap  0.936711  0.935484\n",
       "3  rfc_combined  0.938080  0.936693\n",
       "4       svm_pro  0.935798  0.934165\n",
       "5      svm_prof  0.935798  0.934021\n",
       "6       svm_cap  0.935646  0.933937\n",
       "7  svm_combined  0.935494  0.933833"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_combined', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MN Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "tfidf_data_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "tfidf_data_test_lem = tfidf.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes model accuracy\n",
      "Testing Accuracy: 0.9229\n",
      "\n",
      "F1 Score: 0.9233\n"
     ]
    }
   ],
   "source": [
    "mnb_lemma = MultinomialNB()\n",
    "mnb_lemma.fit(tfidf_data_train_lem, y_train_lem)\n",
    "mnb_test_preds = mnb_lemma.predict(tfidf_data_test_lem)\n",
    "\n",
    "mnb_acc_score_lem = accuracy_score(y_test_lem, mnb_test_preds)\n",
    "mnb_f1_score_lem = f1_score(y_test_lem, mnb_test_preds)\n",
    "print('Multinomial Naive Bayes model accuracy')\n",
    "print(\"Testing Accuracy: {:.4}\".format(mnb_acc_score_lem))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(mnb_f1_score_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(y_test_lem, mnb_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Right', 'Left'], yticklabels=['Right', 'Left'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([13945,  6183,  7323,  8678,  9725,   142,  8214, 10630, 13450,\n",
       "             5728,\n",
       "            ...\n",
       "            17422,  5401,  8138, 14548, 12747, 16922, 17135,  1454,  1501,\n",
       "             9295],\n",
       "           dtype='int64', length=6573)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_lem.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-378-e4180468063b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test_lem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_test_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'right'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1652\u001b[0m             \u001b[0;31m# just raising\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1655\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                     \u001b[0;34m\"is no longer supported, see \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
     ]
    }
   ],
   "source": [
    "test = comments_df.loc[y_test_lem.index]\n",
    "test['pred'] = rf_test_preds\n",
    "test['pred'] = test['pred'].apply(lambda x: 'right' if x == 1 else 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-379-c79d526ba28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mguessed_right_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment_class\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mguessed_right_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mguessed_left_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment_class\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mguessed_left_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "guessed_right_wrong = test[(test.comment_class != test.pred) & (test.pred == 'right')]\n",
    "guessed_right_wrong.reset_index(drop=True, inplace=True)\n",
    "\n",
    "guessed_left_wrong = test[(test.comment_class != test.pred) & (test.pred == 'left')]\n",
    "guessed_left_wrong.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUESSED RIGHT BUT WE WERE WRONG\n",
      "_______________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'guessed_right_wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-380-d7cd6e846f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_______________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguessed_right_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guessed_right_wrong' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"GUESSED RIGHT BUT WE WERE WRONG\")\n",
    "print(\"_______________________________\")\n",
    "for i in range(0,50):\n",
    "    print(guessed_right_wrong.iloc[i].body)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUESSED LEFT BUT WE WERE WRONG\n",
      "______________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'guessed_left_wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-381-4c1d1ba7a9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"______________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguessed_left_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guessed_left_wrong' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"GUESSED LEFT BUT WE WERE WRONG\")\n",
    "print(\"______________________________\")\n",
    "for i in range(0,50):\n",
    "    print(guessed_left_wrong.iloc[i].body)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
