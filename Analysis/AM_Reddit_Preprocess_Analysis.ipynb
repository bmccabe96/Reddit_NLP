{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note, only using comments_df for now until we figure out if it is worth it to use the posts_df as well somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Import Packages, define functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import mysql.connector\n",
    "# some_file.py\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/brianmccabe/DataScience/Flatiron/mod4/Reddit_NLP/Scripts')\n",
    "#import config\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "import scipy\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stopwords(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    \n",
    "    return (len(tokens) - len(stopwords_removed)) / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can define a function that removes stopwords \n",
    "def process_comment(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_percentage(comment):\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    cap_count = 0\n",
    "    for item in tokens:\n",
    "        if item.isupper():\n",
    "            cap_count += 1\n",
    "    return cap_count/len(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_profanity(comment):\n",
    "    profane = pd.read_csv(\"/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/profane_words.csv\", header=None)\n",
    "    profane = list(profane.loc[:,0])\n",
    "    count = 0\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    for word in tokens:\n",
    "        if word in profane:\n",
    "            count += 1\n",
    "    return count/len(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(comment):\n",
    "    comment = comment.lower()\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    \n",
    "    unique_words = len(set(tokens))\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "    return unique_words / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stopwords and punctuations\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords += list(string.punctuation)\n",
    "stopwords += [\"n't\", \"' '\", \"'re'\",\"”\",\"``\",\"“\",\"''\",\"’\",\"'s\",\"'re\",\"http\",\"https\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.read_csv('/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/posts_df.csv', index_col=0)\n",
    "comments_df = pd.read_csv('/Users/alecmccabe/Desktop/Flatiron/Projects/Mod4/Reddit_NLP/csv_data/comments_df_(1).csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151515"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df.columns = ['id_num', 'post_title', 'post_author', 'post_upvote_ratio', 'post_id', 'post_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.columns = ['id_num', 'body', 'comment_id', 'parent_id', 'post_id', 'author', 'score', 'comment_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = '\\w+_(\\w+)'\n",
    "p = re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.post_id = comments_df.post_id.apply(lambda x: p.findall(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RID OF NEGATIVE SCORES (a negative score in a conservative subreddit could be a brigader for example)\n",
    "comments_df = comments_df[comments_df.score > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = comments_df[['body', 'comment_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "right    17116\n",
       "left     15773\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecmccabe/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "leaning_map = {'right': 1, 'left': 0}\n",
    "df.comment_class = df.comment_class.map(leaning_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-67af6b43cc2d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_len'] = df['body'].map(lambda x: len(x))\n"
     ]
    }
   ],
   "source": [
    "df['text_len'] = df['body'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.text_len >= 100]\n",
    "df.drop('text_len', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9389\n",
       "1    9184\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9389\n",
       "0    9389\n",
       "Name: comment_class, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "right = df[df.comment_class == 1]\n",
    "left = df[df.comment_class == 0]\n",
    "\n",
    "right_upsampled = resample(right,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(left), # match number in majority class\n",
    "                          random_state=42) \n",
    "df = pd.concat([left, right_upsampled])\n",
    "df.comment_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['body']\n",
    "y = df['comment_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        As a Lesbian, I get a lot of backlash when peo...\n",
       "1        “*These are radical islamic terrorists and she...\n",
       "2        I hope Gov. Whitmer still has all that extra s...\n",
       "3        She's not wrong. I hope this woman goes places...\n",
       "4        The Orange Tweeter's irresponsible actions hav...\n",
       "                               ...                        \n",
       "18773    Oh heavens, she was pointed and laughed at.  S...\n",
       "18774    Atheist here and this bothers me.  Believe me ...\n",
       "18775    The good news is, if Biden wins and institutes...\n",
       "18776    Not exactly shocking that communities will ban...\n",
       "18777    Because I’m a woman living alone who is in a c...\n",
       "Name: body, Length: 18778, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alecmccabe/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count Stopwords Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_count = X.apply(count_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_train, stop_test, y_train, y_test = train_test_split(stopwords_count, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Pronoun Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from Pronouns import Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Pronouns(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "    \n",
    "#     def count_pronouns(self, comment):\n",
    "#         comment = comment.lower()\n",
    "#         tokens = nltk.word_tokenize(comment)\n",
    "\n",
    "#         pos_tags = [i[1] for i in nltk.pos_tag(tokens)]\n",
    "#         count = 0\n",
    "#         pronouns = ['PRP','PRP$','WP','WP$']\n",
    "#         for pos in pos_tags:\n",
    "#             if pos in pronouns:\n",
    "#                 count += 1\n",
    "\n",
    "#         return count / len(tokens)\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         return pd.Series(X).apply(self.count_pronouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = Pronouns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pronouns()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouns.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns_vector = pronouns.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.106195\n",
       "1        0.048780\n",
       "2        0.058824\n",
       "3        0.107143\n",
       "4        0.029412\n",
       "           ...   \n",
       "18773    0.094340\n",
       "18774    0.054545\n",
       "18775    0.000000\n",
       "18776    0.037037\n",
       "18777    0.037037\n",
       "Name: body, Length: 18778, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouns_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_train, pro_test, y_train, y_test = train_test_split(pronouns_vector, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Capital Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capitalization_Normalizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def capital_percentage(self, lst):\n",
    "        return sum([1 if x.isupper() else 0 for x in lst]) / len(lst)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        tokens = pd.Series(X).apply(nltk.word_tokenize)\n",
    "        return tokens.apply(self.capital_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals = Capitalization_Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capitalization_Normalizer()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitals.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals_vector = capitals.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_train, cap_test, y_train, y_test = train_test_split(capitals_vector, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Profanity Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "profanity_count = X.apply(check_profanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_train, prof_test, y_train, y_test = train_test_split(profanity_count, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Text Length Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = X.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train, len_test, y_train, y_test = train_test_split(text_length, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatize X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply above function to data\n",
    "\n",
    "processed_comments = list(map(process_comment, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with lemmatized output\n",
    "lemmatized_output = []\n",
    "\n",
    "for comment in processed_comments:\n",
    "    lemmed = ' '.join([lemmatizer.lemmatize(w) for w in comment])\n",
    "    lemmatized_output.append(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this to 'lemmatized_output' if you are including lemma (see above)\n",
    "X_lem = lemmatized_output\n",
    "\n",
    "y_lem = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Lexical Diversity Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_div = pd.Series(X_lem).apply(lexical_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_train, lex_test, y_train, y_test = train_test_split(lex_div, y, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.35, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "        self.dim = 300\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Doc.vector defaults to an average of the token vectors.\n",
    "        # https://spacy.io/api/doc#vector\n",
    "        \n",
    "        return [self.nlp(text).vector for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "#         (\"reduce_dim\", TruncatedSVD(50)),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )\n",
    "# embeddings_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = embeddings_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"tfidf\", TfidfVectorizer()),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# tfidf_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = tfidf_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # individual pipelines minus the estimator step: \n",
    "# tfidf_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"tfidf\", TfidfVectorizer()),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# embeddings_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "#         (\"reduce_dim\", TruncatedSVD(50)),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_features = FeatureUnion(\n",
    "#     transformer_list=[\n",
    "#         (\"tfidf\", tfidf_pipeline),\n",
    "#         (\"embeddings\", embeddings_pipeline),\n",
    "#         #(try adding a pipeline that is just the dense columns)\n",
    "#     ]\n",
    "# )\n",
    "# final_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"combined_features\", combined_features),\n",
    "#         (\"classifier\", RandomForestClassifier(random_state=0,n_jobs=-1, verbose=1)),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pipeline.fit(X_train_lem, y_train_lem)\n",
    "# y_pred = final_pipeline.predict(X_test_lem)\n",
    "# cr = classification_report(y_test_lem, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining Sparse with Dense**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_input(pro_tr = None, pro_te = None, \n",
    "                     cap_tr = None, cap_te = None, \n",
    "                     prof_tr = None, prof_te = None, \n",
    "                     len_tr = None, len_te = None,\n",
    "                     lex_tr = None, lex_te = None,\n",
    "                     stop_tr = None, stop_te = None,\n",
    "                     X_train_lem = None, X_test_lem = None):\n",
    "    \n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "    tfidf_data_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "    tfidf_data_test_lem = tfidf.transform(X_test_lem)\n",
    "    \n",
    "    \n",
    "    tfidf_data_train_lem = pd.DataFrame(tfidf_data_train_lem.toarray(), columns=tfidf.vocabulary_.keys())\n",
    "\n",
    "    tfidf_data_test_lem = pd.DataFrame(tfidf_data_test_lem.toarray(), columns=tfidf.vocabulary_.keys())\n",
    "    \n",
    "    print(\"Finished Part 1\")\n",
    "\n",
    "     \n",
    "    if str(type(pro_tr)) != str(type(None)) and str(type(pro_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xpronouns'] = pro_tr\n",
    "        tfidf_data_test_lem['Xpronouns'] = pro_te\n",
    "        print('finished pronoun_test')\n",
    "        \n",
    "    if str(type(cap_tr)) != str(type(None)) and str(type(cap_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xcapitals'] = cap_tr\n",
    "        tfidf_data_test_lem['Xcapitals'] = cap_te\n",
    "        print('finished capital_test')\n",
    "\n",
    "        \n",
    "    if str(type(prof_tr)) != str(type(None)) and str(type(prof_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xprofanity'] = prof_tr\n",
    "        tfidf_data_test_lem['Xprofanity'] = prof_te\n",
    "        print('finished profanity_test')\n",
    "    \n",
    "    if str(type(len_tr)) != str(type(None)) and str(type(len_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xlength'] = len_tr\n",
    "        tfidf_data_test_lem['Xlength'] = len_te\n",
    "        print('finished length_test')\n",
    "    \n",
    "    if str(type(lex_tr)) != str(type(None)) and str(type(lex_tr)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xlexical'] = lex_tr\n",
    "        tfidf_data_test_lem['Xlexical'] = lex_te\n",
    "        print('finished lexical_test')\n",
    "    \n",
    "    if str(type(stop_tr)) != str(type(None)) and str(type(stop_te)) != str(type(None)):\n",
    "        tfidf_data_train_lem['Xstopwords'] = stop_tr\n",
    "        tfidf_data_test_lem['Xstopwords'] = stop_te\n",
    "\n",
    "        \n",
    "    train_columns = tfidf_data_train_lem.columns\n",
    "    \n",
    "    tfidf_data_train_lem = scipy.sparse.csr_matrix(tfidf_data_train_lem)\n",
    "    \n",
    "    print(\"Finished train sparsing\")\n",
    "    \n",
    "    tfidf_data_test_lem = scipy.sparse.csr_matrix(tfidf_data_test_lem)\n",
    "    \n",
    "    print(\"Finished test sparsing\")\n",
    "\n",
    "    \n",
    "    return tfidf_data_train_lem, tfidf_data_test_lem, train_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dif dataframes to test models with, 1 with each feature appended to Tf IDF and one with all 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_columns = classifier_input(X_train_lem = X_train_lem, X_test_lem = X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished pronoun_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished profanity_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished capital_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished length_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n",
      "Finished Part 1\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "pro_train2, pro_test2, pro_columns = classifier_input(pro_tr = pro_train, pro_te = pro_test)\n",
    "\n",
    "prof_train2, prof_test2, prof_columns = classifier_input(prof_tr = prof_train, prof_te = prof_test)\n",
    "\n",
    "cap_train2, cap_test2, cap_columns = classifier_input(cap_tr = cap_train, cap_te = cap_test)\n",
    "\n",
    "len_train2, len_test2, len_columns = classifier_input(len_tr = len_train, len_te = len_test)\n",
    "\n",
    "lex_train2, lex_test2, lex_columns = classifier_input(lex_tr = lex_train, lex_te = lex_test)\n",
    "\n",
    "stop_train2, stop_test2, stop_columns = classifier_input(stop_tr = stop_train, stop_te = stop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished pronoun_test\n",
      "finished capital_test\n",
      "finished profanity_test\n",
      "finished length_test\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "combined_train, combined_test, combined_columns = classifier_input(pro_tr = pro_train, pro_te = pro_test, \n",
    "                                                                   prof_tr = prof_train, prof_te = prof_test, \n",
    "                                                                   cap_tr = cap_train, cap_te = cap_test, \n",
    "                                                                   len_tr = len_train, len_te = len_test, \n",
    "                                                                   lex_tr = lex_train, lex_te = lex_test, \n",
    "                                                                   stop_tr = stop_train, stop_te = stop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, accuracy, f1]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns = ['model','accuracy','f1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No Added Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_basic_tfidf = RandomForestClassifier(n_estimators=200,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_basic_tfidf.fit(X_train, y_train_lem)\n",
    "rf_test_preds = rfc_basic_tfidf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.9414\n",
      "\n",
      "F1 Score: 0.9393\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_basic_tfidf</td>\n",
       "      <td>0.941427</td>\n",
       "      <td>0.939341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy        f1\n",
       "0  rfc_basic_tfidf  0.941427  0.939341"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_basic_tfidf', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Stopwrods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 350 out of 350 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.942\n",
      "\n",
      "F1 Score: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 350 out of 350 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_stop = RandomForestClassifier(n_estimators=350,max_features = 'log2', random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_stop.fit(stop_train2, y_train_lem)\n",
    "rf_test_preds = rfc_stop.predict(stop_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.942036</td>\n",
       "      <td>0.940047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy        f1\n",
       "0  rfc_STOP  0.942036  0.940047"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_STOP', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Pronouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.944\n",
      "\n",
      "F1 Score: 0.9421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_pro = RandomForestClassifier(n_estimators=300,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_pro.fit(pro_train2, y_train_lem)\n",
    "rf_test_preds = rfc_pro.predict(pro_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.942036</td>\n",
       "      <td>0.940047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.944013</td>\n",
       "      <td>0.942120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy        f1\n",
       "0  rfc_STOP  0.942036  0.940047\n",
       "1   rfc_pro  0.944013  0.942120"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_pro', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(pro_columns, rfc_pro.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.021223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.014235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xpronouns</td>\n",
       "      <td>0.008467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.004414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.003908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>biggly</td>\n",
       "      <td>0.003453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>street</td>\n",
       "      <td>0.003442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dissident</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fashioned</td>\n",
       "      <td>0.003156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>instability</td>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0          hoa    0.021223\n",
       "1  underpaying    0.014235\n",
       "2    Xpronouns    0.008467\n",
       "3         bees    0.004414\n",
       "4       jurist    0.003908\n",
       "5       biggly    0.003453\n",
       "6       street    0.003442\n",
       "7    dissident    0.003374\n",
       "8    fashioned    0.003156\n",
       "9  instability    0.003078"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_test_lem, rf_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Right', 'Left'], yticklabels=['Right', 'Left'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RCF Profanity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Profanity\n",
      "Testing Accuracy: 0.9423\n",
      "\n",
      "F1 Score: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_prof = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_prof.fit(prof_train2, y_train_lem)\n",
    "rf_test_preds = rfc_prof.predict(prof_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Profanity')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.942036</td>\n",
       "      <td>0.940047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.944013</td>\n",
       "      <td>0.942120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942340</td>\n",
       "      <td>0.940381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy        f1\n",
       "0  rfc_STOP  0.942036  0.940047\n",
       "1   rfc_pro  0.944013  0.942120\n",
       "2  rfc_prof  0.942340  0.940381"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(prof_columns, rfc_prof.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.022268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.013726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xprofanity</td>\n",
       "      <td>0.008456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.004349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.003939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dissident</td>\n",
       "      <td>0.003340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>street</td>\n",
       "      <td>0.003195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>biggly</td>\n",
       "      <td>0.003154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fashioned</td>\n",
       "      <td>0.002989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>instability</td>\n",
       "      <td>0.002767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0          hoa    0.022268\n",
       "1  underpaying    0.013726\n",
       "2   Xprofanity    0.008456\n",
       "3         bees    0.004349\n",
       "4       jurist    0.003939\n",
       "5    dissident    0.003340\n",
       "6       street    0.003195\n",
       "7       biggly    0.003154\n",
       "8    fashioned    0.002989\n",
       "9  instability    0.002767"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's interesting that we have a lower accuracy with this model, yet our newly added feature ranks as higher importance than pronouns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Capital**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9399\n",
      "\n",
      "F1 Score: 0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_cap = RandomForestClassifier(n_estimators=200,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_cap.fit(cap_train2, y_train_lem)\n",
    "rf_test_preds = rfc_cap.predict(cap_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.942036</td>\n",
       "      <td>0.940047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.944013</td>\n",
       "      <td>0.942120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942340</td>\n",
       "      <td>0.940381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>0.937922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy        f1\n",
       "0  rfc_STOP  0.942036  0.940047\n",
       "1   rfc_pro  0.944013  0.942120\n",
       "2  rfc_prof  0.942340  0.940381\n",
       "3   rfc_cap  0.939906  0.937922"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_cap', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(cap_columns, rfc_cap.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.022783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.013896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xcapitals</td>\n",
       "      <td>0.006555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.004579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.003943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>street</td>\n",
       "      <td>0.003572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dissident</td>\n",
       "      <td>0.003439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>biggly</td>\n",
       "      <td>0.003220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fashioned</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>instability</td>\n",
       "      <td>0.003082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0          hoa    0.022783\n",
       "1  underpaying    0.013896\n",
       "2    Xcapitals    0.006555\n",
       "3         bees    0.004579\n",
       "4       jurist    0.003943\n",
       "5       street    0.003572\n",
       "6    dissident    0.003439\n",
       "7       biggly    0.003220\n",
       "8    fashioned    0.003101\n",
       "9  instability    0.003082"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9422\n",
      "\n",
      "F1 Score: 0.9403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_len = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_len.fit(len_train2, y_train_lem)\n",
    "rf_test_preds = rfc_len.predict(len_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.942036</td>\n",
       "      <td>0.940047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.944013</td>\n",
       "      <td>0.942120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942340</td>\n",
       "      <td>0.940381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>0.937922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942188</td>\n",
       "      <td>0.940252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy        f1\n",
       "0  rfc_STOP  0.942036  0.940047\n",
       "1   rfc_pro  0.944013  0.942120\n",
       "2  rfc_prof  0.942340  0.940381\n",
       "3   rfc_cap  0.939906  0.937922\n",
       "4   rfc_len  0.942188  0.940252"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_len', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Lexical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Lexical\n",
      "Testing Accuracy: 0.9436\n",
      "\n",
      "F1 Score: 0.9416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_lex = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_lex.fit(lex_train2, y_train_lem)\n",
    "rf_test_preds = rfc_lex.predict(lex_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Lexical')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.942036</td>\n",
       "      <td>0.940047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.944013</td>\n",
       "      <td>0.942120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942340</td>\n",
       "      <td>0.940381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>0.937922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942188</td>\n",
       "      <td>0.940252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.943557</td>\n",
       "      <td>0.941602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy        f1\n",
       "0  rfc_STOP  0.942036  0.940047\n",
       "1   rfc_pro  0.944013  0.942120\n",
       "2  rfc_prof  0.942340  0.940381\n",
       "3   rfc_cap  0.939906  0.937922\n",
       "4   rfc_len  0.942188  0.940252\n",
       "5   rfc_lex  0.943557  0.941602"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_lex', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Combined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 350 out of 350 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9388\n",
      "\n",
      "F1 Score: 0.9366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 350 out of 350 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_combined = RandomForestClassifier(n_estimators=350,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_combined.fit(combined_train, y_train_lem)\n",
    "rf_test_preds = rfc_combined.predict(combined_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.942036</td>\n",
       "      <td>0.940047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.944013</td>\n",
       "      <td>0.942120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942340</td>\n",
       "      <td>0.940381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>0.937922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942188</td>\n",
       "      <td>0.940252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.943557</td>\n",
       "      <td>0.941602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.938841</td>\n",
       "      <td>0.936633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0      rfc_STOP  0.942036  0.940047\n",
       "1       rfc_pro  0.944013  0.942120\n",
       "2      rfc_prof  0.942340  0.940381\n",
       "3       rfc_cap  0.939906  0.937922\n",
       "4       rfc_len  0.942188  0.940252\n",
       "5       rfc_lex  0.943557  0.941602\n",
       "6  rfc_combined  0.938841  0.936633"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_combined', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(list(zip(combined_columns, rfc_combined.feature_importances_)),key=lambda x: x[1], reverse=True),\n",
    "             columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoa</td>\n",
       "      <td>0.017135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>underpaying</td>\n",
       "      <td>0.013944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xprofanity</td>\n",
       "      <td>0.008268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xstopwords</td>\n",
       "      <td>0.007988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xlength</td>\n",
       "      <td>0.007789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xpronouns</td>\n",
       "      <td>0.007772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Xcapitals</td>\n",
       "      <td>0.006088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Xlexical</td>\n",
       "      <td>0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bees</td>\n",
       "      <td>0.004388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jurist</td>\n",
       "      <td>0.003672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0          hoa    0.017135\n",
       "1  underpaying    0.013944\n",
       "2   Xprofanity    0.008268\n",
       "3   Xstopwords    0.007988\n",
       "4      Xlength    0.007789\n",
       "5    Xpronouns    0.007772\n",
       "6    Xcapitals    0.006088\n",
       "7     Xlexical    0.005682\n",
       "8         bees    0.004388\n",
       "9       jurist    0.003672"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gridsearch RFC Combined**\n",
    "- currently this has been replaced with combined(lexical + profanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 55, 60, 65, 70, 75, 80, 85, 90, 95]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(50,100,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = list(range(50,250,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 33.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 39.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 60, 70, 80, 90, 100, 110, 120,\n",
       "                                          130, 140, 150, 160, 170, 180, 190,\n",
       "                                          200, 210, 220, 230, 240]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'criterion': ['gini','entropy'],\n",
    "              'max_features': ['auto','sqrt','log2']\n",
    "        }\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, refit = True, verbose = 3, n_jobs = -1, scoring='accuracy')\n",
    "\n",
    "grid.fit(lex_prof_train, y_train_lem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_test_preds = grid.predict(lex_prof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'log2',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 240,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_lem, grid_test_preds)\n",
    "f1 = f1_score(y_test_lem, grid_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid RFC with Lemmatization Features and Combined\n",
      "Testing Accuracy: 0.9402\n",
      "\n",
      "F1 Score: 0.9383\n"
     ]
    }
   ],
   "source": [
    "print('Grid RFC with Lemmatization Features and Combined')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rfc_lex_prof</td>\n",
       "      <td>0.941427</td>\n",
       "      <td>0.939437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>grid_rfc_comb_lex_prof</td>\n",
       "      <td>0.940210</td>\n",
       "      <td>0.938295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  accuracy        f1\n",
       "0                  rfc_pro  0.934124  0.932712\n",
       "1                 rfc_prof  0.933516  0.932238\n",
       "2                  rfc_cap  0.936711  0.935484\n",
       "3                  rfc_len  0.938993  0.937510\n",
       "4                  rfc_len  0.940362  0.939112\n",
       "5             rfc_combined  0.936254  0.934847\n",
       "6        grid_rfc_combined  0.934581  0.933147\n",
       "7                  svm_pro  0.935798  0.934165\n",
       "8                 svm_prof  0.935798  0.934021\n",
       "9                  rfc_lex  0.940362  0.939112\n",
       "10            rfc_lex_prof  0.941427  0.939437\n",
       "11  grid_rfc_comb_lex_prof  0.940210  0.938295"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'grid_rfc_comb_lex_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFC Combined (Lexical + Prof)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished profanity_test\n",
      "finished lexical_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "lex_prof_train, lex_prof_test, lex_prof_columns = classifier_input(prof_tr = prof_train, prof_te = prof_test, \n",
    "                                                                   lex_tr = lex_train, lex_te = lex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9414\n",
      "\n",
      "F1 Score: 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_lex_prof = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_lex_prof.fit(lex_prof_train, y_train_lem)\n",
    "rf_test_preds = rfc_lex_prof.predict(lex_prof_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.942036</td>\n",
       "      <td>0.940047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.944013</td>\n",
       "      <td>0.942120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942340</td>\n",
       "      <td>0.940381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>0.937922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942188</td>\n",
       "      <td>0.940252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.943557</td>\n",
       "      <td>0.941602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.938841</td>\n",
       "      <td>0.936633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rfc_lex_prof</td>\n",
       "      <td>0.941427</td>\n",
       "      <td>0.939475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0      rfc_STOP  0.942036  0.940047\n",
       "1       rfc_pro  0.944013  0.942120\n",
       "2      rfc_prof  0.942340  0.940381\n",
       "3       rfc_cap  0.939906  0.937922\n",
       "4       rfc_len  0.942188  0.940252\n",
       "5       rfc_lex  0.943557  0.941602\n",
       "6  rfc_combined  0.938841  0.936633\n",
       "7  rfc_lex_prof  0.941427  0.939475"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_lex_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open('rfc_lex_prof.pickle', 'wb') as f:\n",
    "    pickle.dump(rfc_lex_prof, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Above .94s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Part 1\n",
      "finished pronoun_test\n",
      "finished profanity_test\n",
      "finished length_test\n",
      "Finished train sparsing\n",
      "Finished test sparsing\n"
     ]
    }
   ],
   "source": [
    "top_train, top_test, top_columns = classifier_input(pro_tr = pro_train, pro_te = pro_test, \n",
    "                                                                   prof_tr = prof_train, prof_te = prof_test, \n",
    "                                                                   len_tr = len_train, len_te = len_test,  \n",
    "                                                                   stop_tr = stop_train, stop_te = stop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Lemmatization Features and Capitalization\n",
      "Testing Accuracy: 0.9405\n",
      "\n",
      "F1 Score: 0.9386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_top = RandomForestClassifier(n_estimators=250,max_features='log2',random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_top.fit(top_train, y_train_lem)\n",
    "rf_test_preds = rfc_top.predict(top_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('Random Forest with Lemmatization Features and Capitalization')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_STOP</td>\n",
       "      <td>0.942036</td>\n",
       "      <td>0.940047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.944013</td>\n",
       "      <td>0.942120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.942340</td>\n",
       "      <td>0.940381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>0.937922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.942188</td>\n",
       "      <td>0.940252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_lex</td>\n",
       "      <td>0.943557</td>\n",
       "      <td>0.941602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.938841</td>\n",
       "      <td>0.936633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rfc_lex_prof</td>\n",
       "      <td>0.941427</td>\n",
       "      <td>0.939475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rfc_top</td>\n",
       "      <td>0.940514</td>\n",
       "      <td>0.938647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0      rfc_STOP  0.942036  0.940047\n",
       "1       rfc_pro  0.944013  0.942120\n",
       "2      rfc_prof  0.942340  0.940381\n",
       "3       rfc_cap  0.939906  0.937922\n",
       "4       rfc_len  0.942188  0.940252\n",
       "5       rfc_lex  0.943557  0.941602\n",
       "6  rfc_combined  0.938841  0.936633\n",
       "7  rfc_lex_prof  0.941427  0.939475\n",
       "8       rfc_top  0.940514  0.938647"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'rfc_top', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with Pronouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Pronouns\n",
      "Testing Accuracy: 0.9358\n",
      "\n",
      "F1 Score: 0.9342\n"
     ]
    }
   ],
   "source": [
    "svc_pro = SVC(verbose=1)\n",
    "svc_pro.fit(pro_train2, y_train_lem)\n",
    "rf_test_preds = svc_pro.predict(pro_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Pronouns')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy        f1\n",
       "0            rfc_pro  0.934124  0.932712\n",
       "1           rfc_prof  0.933516  0.932238\n",
       "2            rfc_cap  0.936711  0.935484\n",
       "3            rfc_len  0.938993  0.937510\n",
       "4            rfc_len  0.940362  0.939112\n",
       "5       rfc_combined  0.936254  0.934847\n",
       "6  grid_rfc_combined  0.934581  0.933147\n",
       "7            svm_pro  0.935798  0.934165"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_pro', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with Profanity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Profanity\n",
      "Testing Accuracy: 0.9358\n",
      "\n",
      "F1 Score: 0.934\n"
     ]
    }
   ],
   "source": [
    "svc_prof = SVC(verbose=1)\n",
    "svc_prof.fit(prof_train2, y_train_lem)\n",
    "rf_test_preds = svc_prof.predict(prof_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Profanity')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_len</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.936254</td>\n",
       "      <td>0.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_rfc_combined</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.933147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy        f1\n",
       "0            rfc_pro  0.934124  0.932712\n",
       "1           rfc_prof  0.933516  0.932238\n",
       "2            rfc_cap  0.936711  0.935484\n",
       "3            rfc_len  0.938993  0.937510\n",
       "4            rfc_len  0.940362  0.939112\n",
       "5       rfc_combined  0.936254  0.934847\n",
       "6  grid_rfc_combined  0.934581  0.933147\n",
       "7            svm_pro  0.935798  0.934165\n",
       "8           svm_prof  0.935798  0.934021"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_prof', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Capitals\n",
      "Testing Accuracy: 0.9356\n",
      "\n",
      "F1 Score: 0.9339\n"
     ]
    }
   ],
   "source": [
    "svc_cap = SVC(verbose=1)\n",
    "svc_cap.fit(cap_train2, y_train_lem)\n",
    "rf_test_preds = svc_cap.predict(cap_test2)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Capitals')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.936693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm_cap</td>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.933937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0       rfc_pro  0.934124  0.932712\n",
       "1      rfc_prof  0.933516  0.932238\n",
       "2       rfc_cap  0.936711  0.935484\n",
       "3  rfc_combined  0.938080  0.936693\n",
       "4       svm_pro  0.935798  0.934165\n",
       "5      svm_prof  0.935798  0.934021\n",
       "6       svm_cap  0.935646  0.933937"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_cap', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVM with Lemmatization Features and Capitals\n",
      "Testing Accuracy: 0.9355\n",
      "\n",
      "F1 Score: 0.9338\n"
     ]
    }
   ],
   "source": [
    "svc_combined = SVC(verbose=1)\n",
    "svc_combined.fit(combined_train, y_train_lem)\n",
    "rf_test_preds = svc_combined.predict(combined_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_lem, rf_test_preds)\n",
    "f1 = f1_score(y_test_lem, rf_test_preds)\n",
    "print('SVM with Lemmatization Features and Capitals')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc_pro</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.932712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc_prof</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.932238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc_cap</td>\n",
       "      <td>0.936711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc_combined</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.936693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_pro</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_prof</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.934021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm_cap</td>\n",
       "      <td>0.935646</td>\n",
       "      <td>0.933937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_combined</td>\n",
       "      <td>0.935494</td>\n",
       "      <td>0.933833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy        f1\n",
       "0       rfc_pro  0.934124  0.932712\n",
       "1      rfc_prof  0.933516  0.932238\n",
       "2       rfc_cap  0.936711  0.935484\n",
       "3  rfc_combined  0.938080  0.936693\n",
       "4       svm_pro  0.935798  0.934165\n",
       "5      svm_prof  0.935798  0.934021\n",
       "6       svm_cap  0.935646  0.933937\n",
       "7  svm_combined  0.935494  0.933833"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model': 'svm_combined', 'accuracy': accuracy, 'f1': f1}\n",
    "results = results.append(new_row, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MN Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_data_train_lem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-fff38b1f0c0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmnb_lemma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmnb_lemma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_data_train_lem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_lem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmnb_test_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnb_lemma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_data_test_lem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmnb_acc_score_lem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_lem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnb_test_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfidf_data_train_lem' is not defined"
     ]
    }
   ],
   "source": [
    "mnb_lemma = MultinomialNB()\n",
    "mnb_lemma.fit(tfidf_data_train_lem, y_train_lem)\n",
    "mnb_test_preds = mnb_lemma.predict(tfidf_data_test_lem)\n",
    "\n",
    "mnb_acc_score_lem = accuracy_score(y_test_lem, mnb_test_preds)\n",
    "mnb_f1_score_lem = f1_score(y_test_lem, mnb_test_preds)\n",
    "print('Multinomial Naive Bayes model accuracy')\n",
    "print(\"Testing Accuracy: {:.4}\".format(mnb_acc_score_lem))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(mnb_f1_score_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(y_test_lem, mnb_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Right', 'Left'], yticklabels=['Right', 'Left'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([13945,  6183,  7323,  8678,  9725,   142,  8214, 10630, 13450,\n",
       "             5728,\n",
       "            ...\n",
       "            17422,  5401,  8138, 14548, 12747, 16922, 17135,  1454,  1501,\n",
       "             9295],\n",
       "           dtype='int64', length=6573)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_lem.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-378-e4180468063b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test_lem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_test_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'right'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1652\u001b[0m             \u001b[0;31m# just raising\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1655\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                     \u001b[0;34m\"is no longer supported, see \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
     ]
    }
   ],
   "source": [
    "test = comments_df.loc[y_test_lem.index]\n",
    "test['pred'] = rf_test_preds\n",
    "test['pred'] = test['pred'].apply(lambda x: 'right' if x == 1 else 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-379-c79d526ba28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mguessed_right_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment_class\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mguessed_right_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mguessed_left_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment_class\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mguessed_left_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "guessed_right_wrong = test[(test.comment_class != test.pred) & (test.pred == 'right')]\n",
    "guessed_right_wrong.reset_index(drop=True, inplace=True)\n",
    "\n",
    "guessed_left_wrong = test[(test.comment_class != test.pred) & (test.pred == 'left')]\n",
    "guessed_left_wrong.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUESSED RIGHT BUT WE WERE WRONG\n",
      "_______________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'guessed_right_wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-380-d7cd6e846f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_______________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguessed_right_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guessed_right_wrong' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"GUESSED RIGHT BUT WE WERE WRONG\")\n",
    "print(\"_______________________________\")\n",
    "for i in range(0,50):\n",
    "    print(guessed_right_wrong.iloc[i].body)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUESSED LEFT BUT WE WERE WRONG\n",
      "______________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'guessed_left_wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-381-4c1d1ba7a9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"______________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguessed_left_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guessed_left_wrong' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"GUESSED LEFT BUT WE WERE WRONG\")\n",
    "print(\"______________________________\")\n",
    "for i in range(0,50):\n",
    "    print(guessed_left_wrong.iloc[i].body)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
